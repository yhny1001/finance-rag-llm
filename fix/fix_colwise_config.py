#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¿®å¤Qwen3æ¨¡å‹é…ç½®ä¸­çš„colwise tensor parallelé—®é¢˜
"""

import json
import shutil
from pathlib import Path
from config import Config

def fix_model_config():
    """ä¿®å¤æ¨¡å‹é…ç½®æ–‡ä»¶"""
    print("ğŸ”§ ä¿®å¤æ¨¡å‹é…ç½®ä¸­çš„colwiseé—®é¢˜...")
    
    try:
        model_path = Path(Config.LLM_MODEL_PATH)
        config_file = model_path / "config.json"
        
        if not config_file.exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return False
        
        print(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_file}")
        
        # å¤‡ä»½
        backup_file = config_file.with_suffix('.json.backup')
        if not backup_file.exists():
            shutil.copy2(config_file, backup_file)
            print(f"ğŸ“¦ å·²å¤‡ä»½åˆ°: {backup_file}")
        
        # è¯»å–é…ç½®
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        print("ğŸ“‹ å½“å‰é…ç½®:")
        for key in ['tensor_parallel_style', 'tensor_parallel_size', 'quantization_config']:
            if key in config:
                print(f"  {key}: {config[key]}")
        
        # ä¿®å¤é—®é¢˜é…ç½®
        changes_made = False
        
        # 1. ç§»é™¤æˆ–ä¿®å¤tensor_parallel_style
        if 'tensor_parallel_style' in config:
            if config['tensor_parallel_style'] == 'colwise':
                print("ğŸ”§ ç§»é™¤colwise tensor_parallel_style...")
                del config['tensor_parallel_style']
                changes_made = True
            elif config['tensor_parallel_style'] not in ['fsdp', 'deepspeed', 'megatron', 'torchpaxus']:
                print(f"ğŸ”§ ä¿®å¤ä¸æ”¯æŒçš„tensor_parallel_style: {config['tensor_parallel_style']}")
                config['tensor_parallel_style'] = 'fsdp'
                changes_made = True
        
        # 2. æ£€æŸ¥å…¶ä»–å¹¶è¡Œç›¸å…³é…ç½®
        parallel_keys = [
            'tensor_parallel_size', 
            'pipeline_model_parallel_size',
            'data_parallel_size'
        ]
        
        for key in parallel_keys:
            if key in config and config[key] != 1:
                print(f"ğŸ”§ é‡ç½®{key}ä¸º1...")
                config[key] = 1
                changes_made = True
        
        # 3. æ·»åŠ å®‰å…¨çš„å¹¶è¡Œé…ç½®
        safe_parallel_config = {
            'use_cache': True,
            'torch_dtype': 'float16'
        }
        
        for key, value in safe_parallel_config.items():
            if key not in config:
                config[key] = value
                changes_made = True
        
        # ä¿å­˜ä¿®å¤åçš„é…ç½®
        if changes_made:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            print("âœ… é…ç½®æ–‡ä»¶å·²ä¿®å¤")
            
            # æ˜¾ç¤ºä¿®å¤åçš„é…ç½®
            print("\nğŸ“‹ ä¿®å¤åé…ç½®:")
            for key in ['tensor_parallel_style', 'tensor_parallel_size', 'torch_dtype']:
                if key in config:
                    print(f"  {key}: {config[key]}")
            
            return True
        else:
            print("âœ… é…ç½®æ–‡ä»¶æ— éœ€ä¿®å¤")
            return True
            
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_fixed_config():
    """æµ‹è¯•ä¿®å¤åçš„é…ç½®"""
    print("\nğŸ§ª æµ‹è¯•ä¿®å¤åçš„é…ç½®...")
    
    try:
        from transformers import AutoConfig
        
        model_path = Config.LLM_MODEL_PATH
        config = AutoConfig.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥å…³é”®é…ç½®
        parallel_attrs = [
            'tensor_parallel_style',
            'tensor_parallel_size', 
            'pipeline_model_parallel_size'
        ]
        
        for attr in parallel_attrs:
            if hasattr(config, attr):
                value = getattr(config, attr)
                print(f"  {attr}: {value}")
                
                if attr == 'tensor_parallel_style' and value == 'colwise':
                    print("âš ï¸ colwiseé—®é¢˜ä»ç„¶å­˜åœ¨")
                    return False
        
        print("âœ… é…ç½®æ£€æŸ¥é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def restore_config():
    """æ¢å¤é…ç½®æ–‡ä»¶"""
    print("\nğŸ”„ é…ç½®æ¢å¤è¯´æ˜...")
    
    try:
        model_path = Path(Config.LLM_MODEL_PATH)
        backup_file = model_path / "config.json.backup"
        config_file = model_path / "config.json"
        
        if backup_file.exists():
            print(f"ğŸ’¡ å¦‚éœ€æ¢å¤åŸå§‹é…ç½®ï¼Œè¯·è¿è¡Œï¼š")
            print(f"   cp {backup_file} {config_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¢å¤è¯´æ˜å¤±è´¥: {e}")
        return False

def main():
    """ä¸»ä¿®å¤æµç¨‹"""
    print("ğŸ”§ ä¿®å¤Qwen3 colwiseé…ç½®é—®é¢˜")
    print("=" * 50)
    
    steps = [
        ("ä¿®å¤æ¨¡å‹é…ç½®", fix_model_config),
        ("æµ‹è¯•ä¿®å¤é…ç½®", test_fixed_config)
    ]
    
    success_count = 0
    for step_name, step_func in steps:
        print(f"\nğŸ”§ {step_name}...")
        if step_func():
            print(f"âœ… {step_name}æˆåŠŸ")
            success_count += 1
        else:
            print(f"âŒ {step_name}å¤±è´¥")
            break
    
    if success_count == len(steps):
        print("\nğŸ‰ colwiseé…ç½®ä¿®å¤å®Œæˆï¼")
        restore_config()
        return True
    else:
        print("\nâŒ colwiseé…ç½®ä¿®å¤å¤±è´¥")
        restore_config()
        return False

if __name__ == "__main__":
    main() 