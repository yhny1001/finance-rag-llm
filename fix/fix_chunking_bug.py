"""
ä¿®å¤æ–‡æ¡£åˆ‡ç‰‡ç®—æ³•BUGå¹¶é‡å»ºå‘é‡æ•°æ®åº“
è§£å†³åˆ‡ç‰‡é‡å¤ã€ç‰‡æ®µè¿‡çŸ­ç­‰é—®é¢˜
"""

import os
import shutil
from pathlib import Path
from vector_db import VectorDatabase
from rag_engine import RAGEngine
from config_improved import ImprovedConfig

def analyze_current_chunking_bug():
    """åˆ†æå½“å‰åˆ‡ç‰‡ç®—æ³•çš„é—®é¢˜"""
    print("ğŸ” åˆ†æå½“å‰åˆ‡ç‰‡ç®—æ³•é—®é¢˜")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿå½“å‰åˆ‡ç‰‡ç®—æ³•
    test_text = "ç›®çš„å‘ç”Ÿé¢åˆ†æå¡«åˆ—ã€‚å‡€åˆ©æ¶¦ï¼Œæ˜¯æŒ‡èèµ„æ€§æ‹…ä¿æœºæ„å®ç°çš„å‡€åˆ©æ¶¦ï¼›å¦‚ä¸ºå‡€äºæŸï¼Œå‰åŠ \"-\"å·å¡«åˆ—ã€‚è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥éªŒè¯åˆ‡ç‰‡ç®—æ³•ã€‚"
    
    print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")
    print(f"æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    
    # å½“å‰æœ‰é—®é¢˜çš„åˆ‡ç‰‡é€»è¾‘
    chunk_size = 512
    chunk_overlap = 50
    
    print(f"\nå½“å‰é…ç½®: CHUNK_SIZE={chunk_size}, CHUNK_OVERLAP={chunk_overlap}")
    
    # æ¨¡æ‹Ÿæœ‰é—®é¢˜çš„åˆ‡ç‰‡ç®—æ³•
    chunks = []
    start = 0
    
    while start < len(test_text):
        end = start + chunk_size
        
        # è¿™é‡Œå¯èƒ½æ˜¯é—®é¢˜æ‰€åœ¨ - é”™è¯¯çš„è¾¹ç•Œå¤„ç†
        if end < len(test_text):
            for sep in ['\n\n', '\n', 'ã€‚', 'ï¼', 'ï¼Ÿ', ';', '.']:
                sep_pos = test_text.rfind(sep, start, end)
                if sep_pos > start:
                    end = sep_pos + len(sep)
                    break
        
        chunk = test_text[start:end].strip()
        if chunk:
            chunks.append((start, end, chunk))
        
        # è¿™é‡Œå¯èƒ½æœ‰BUG
        start = max(start + 1, end - chunk_overlap)  # é—®é¢˜ï¼šstart + 1 å¯¼è‡´é‡å¤åˆ‡ç‰‡
    
    print(f"\næœ‰é—®é¢˜çš„åˆ‡ç‰‡ç»“æœ ({len(chunks)} ä¸ªç‰‡æ®µ):")
    for i, (start, end, chunk) in enumerate(chunks[:5]):
        print(f"  {i+1}. [{start}:{end}] (é•¿åº¦{len(chunk)}): {repr(chunk)}")

def backup_current_database():
    """å¤‡ä»½å½“å‰å‘é‡æ•°æ®åº“"""
    print("\nğŸ’¾ å¤‡ä»½å½“å‰å‘é‡æ•°æ®åº“")
    print("-" * 30)
    
    if os.path.exists("vector_db"):
        backup_dir = "vector_db_backup"
        if os.path.exists(backup_dir):
            shutil.rmtree(backup_dir)
        shutil.copytree("vector_db", backup_dir)
        print(f"âœ… å·²å¤‡ä»½åˆ° {backup_dir}")
    else:
        print("âš ï¸ å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½")

def clear_problematic_database():
    """æ¸…ç†æœ‰é—®é¢˜çš„å‘é‡æ•°æ®åº“"""
    print("\nğŸ—‘ï¸ æ¸…ç†æœ‰é—®é¢˜çš„å‘é‡æ•°æ®åº“")
    print("-" * 30)
    
    if os.path.exists("vector_db"):
        # åªä¿ç•™æ¼”ç¤ºæ–‡ä»¶ï¼Œåˆ é™¤çœŸå®æ•°æ®åº“æ–‡ä»¶
        for file in os.listdir("vector_db"):
            if not file.startswith("demo_"):
                file_path = os.path.join("vector_db", file)
                try:
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                        print(f"åˆ é™¤æ–‡ä»¶: {file}")
                    elif os.path.isdir(file_path):
                        shutil.rmtree(file_path)
                        print(f"åˆ é™¤ç›®å½•: {file}")
                except Exception as e:
                    print(f"åˆ é™¤ {file} æ—¶å‡ºé”™: {e}")
        print("âœ… æ¸…ç†å®Œæˆ")
    else:
        print("âš ï¸ å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨")

def test_improved_chunking():
    """æµ‹è¯•æ”¹è¿›çš„åˆ‡ç‰‡ç®—æ³•"""
    print("\nğŸ”§ æµ‹è¯•æ”¹è¿›çš„åˆ‡ç‰‡ç®—æ³•")
    print("-" * 30)
    
    test_text = "ç›®çš„å‘ç”Ÿé¢åˆ†æå¡«åˆ—ã€‚å‡€åˆ©æ¶¦ï¼Œæ˜¯æŒ‡èèµ„æ€§æ‹…ä¿æœºæ„å®ç°çš„å‡€åˆ©æ¶¦ï¼›å¦‚ä¸ºå‡€äºæŸï¼Œå‰åŠ \"-\"å·å¡«åˆ—ã€‚è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥éªŒè¯åˆ‡ç‰‡ç®—æ³•ã€‚é“¶è¡Œåº”å½“å»ºç«‹å®Œå–„çš„é£é™©ç®¡ç†ä½“ç³»ï¼ŒåŒ…æ‹¬é£é™©è¯†åˆ«ã€é£é™©è¯„ä¼°ã€é£é™©æ§åˆ¶ç­‰ç¯èŠ‚ã€‚å•†ä¸šé“¶è¡Œçš„èµ„æœ¬å……è¶³ç‡ä¸å¾—ä½äº8%ï¼Œä¸€çº§èµ„æœ¬å……è¶³ç‡ä¸å¾—ä½äº6%ã€‚"
    
    print(f"æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    
    # æ”¹è¿›çš„åˆ‡ç‰‡ç®—æ³•
    chunk_size = ImprovedConfig.CHUNK_SIZE  # 1000
    chunk_overlap = ImprovedConfig.CHUNK_OVERLAP  # 200
    
    print(f"æ”¹è¿›é…ç½®: CHUNK_SIZE={chunk_size}, CHUNK_OVERLAP={chunk_overlap}")
    
    chunks = []
    start = 0
    
    while start < len(test_text):
        end = min(start + chunk_size, len(test_text))
        
        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªç‰‡æ®µï¼Œå°è¯•åœ¨å¥å·ç­‰ä½ç½®åˆ‡åˆ†
        if end < len(test_text):
            for sep in ['ã€‚', 'ï¼', 'ï¼Ÿ', '\n\n', '\n', ';', '.']:
                sep_pos = test_text.rfind(sep, start + chunk_size // 2, end)  # åœ¨ååŠéƒ¨åˆ†å¯»æ‰¾åˆ†éš”ç¬¦
                if sep_pos > start:
                    end = sep_pos + len(sep)
                    break
        
        chunk = test_text[start:end].strip()
        if chunk and len(chunk) >= 20:  # è¿‡æ»¤æ‰è¿‡çŸ­çš„ç‰‡æ®µ
            chunks.append((start, end, chunk))
        
        # ä¿®æ­£ï¼šæ­£ç¡®çš„æ­¥é•¿è®¡ç®—
        if end >= len(test_text):
            break
        start = end - chunk_overlap  # æ­£ç¡®çš„é‡å è®¡ç®—
        
        # é˜²æ­¢æ— é™å¾ªç¯
        if start <= 0:
            start = end // 2
    
    print(f"\næ”¹è¿›çš„åˆ‡ç‰‡ç»“æœ ({len(chunks)} ä¸ªç‰‡æ®µ):")
    for i, (start, end, chunk) in enumerate(chunks):
        print(f"  {i+1}. [{start}:{end}] (é•¿åº¦{len(chunk)}): {repr(chunk[:100])}...")

def rebuild_with_improved_config():
    """ä½¿ç”¨æ”¹è¿›é…ç½®é‡å»ºå‘é‡æ•°æ®åº“"""
    print("\nğŸš€ ä½¿ç”¨æ”¹è¿›é…ç½®é‡å»ºå‘é‡æ•°æ®åº“")
    print("=" * 50)
    
    # ä¸´æ—¶ä¿®æ”¹é…ç½®å¯¼å…¥
    import sys
    sys.modules['config'] = __import__('config_improved')
    
    try:
        # ä½¿ç”¨æ”¹è¿›é…ç½®åˆ›å»ºRAGå¼•æ“
        from config_improved import ImprovedConfig as Config
        
        print("é…ç½®å‚æ•°:")
        print(f"  CHUNK_SIZE: {Config.CHUNK_SIZE}")
        print(f"  CHUNK_OVERLAP: {Config.CHUNK_OVERLAP}")
        print(f"  TOP_K: {Config.TOP_K}")
        print(f"  SIMILARITY_THRESHOLD: {Config.SIMILARITY_THRESHOLD}")
        
        # åˆ›å»ºRAGå¼•æ“å¹¶é‡å»ºç´¢å¼•
        rag_engine = RAGEngine()
        print("\nå¼€å§‹é‡å»ºå‘é‡ç´¢å¼•...")
        rag_engine.build_index(force_rebuild=True)
        
        # éªŒè¯é‡å»ºç»“æœ
        stats = rag_engine.get_vector_db_stats()
        print(f"\nâœ… é‡å»ºå®Œæˆï¼å‘é‡æ•°æ®åº“ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é‡å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def verify_fix():
    """éªŒè¯ä¿®å¤æ•ˆæœ"""
    print("\nâœ… éªŒè¯ä¿®å¤æ•ˆæœ")
    print("=" * 50)
    
    try:
        # åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“å®ä¾‹è¿›è¡ŒéªŒè¯
        vdb = VectorDatabase()
        if not vdb.load_from_disk():
            print("âŒ æ— æ³•åŠ è½½é‡å»ºåçš„å‘é‡æ•°æ®åº“")
            return False
        
        stats = vdb.get_statistics()
        total_chunks = len(vdb.document_store)
        
        print(f"é‡å»ºåç»Ÿè®¡:")
        print(f"  æ€»ç‰‡æ®µæ•°: {total_chunks}")
        
        # åˆ†ææ–°çš„ç‰‡æ®µè´¨é‡
        chunk_lengths = []
        short_chunks = 0
        empty_chunks = 0
        
        for chunk_data in vdb.document_store.values():
            length = len(chunk_data.get('text', ''))
            chunk_lengths.append(length)
            if length < 50:
                short_chunks += 1
            if length < 10:
                empty_chunks += 1
        
        avg_length = sum(chunk_lengths) / len(chunk_lengths)
        
        print(f"  å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
        print(f"  çŸ­ç‰‡æ®µç‡: {short_chunks/total_chunks*100:.1f}% (ç›®æ ‡<5%)")
        print(f"  ç©ºç‰‡æ®µç‡: {empty_chunks/total_chunks*100:.1f}% (ç›®æ ‡<1%)")
        
        # è´¨é‡è¯„ä¼°
        if short_chunks/total_chunks < 0.05 and empty_chunks/total_chunks < 0.01:
            print("âœ… åˆ‡ç‰‡è´¨é‡æ˜¾è‘—æ”¹å–„!")
            return True
        else:
            print("âš ï¸ åˆ‡ç‰‡è´¨é‡ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
            return False
    
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ› ï¸ æ–‡æ¡£åˆ‡ç‰‡BUGä¿®å¤å·¥å…·")
    print("=" * 60)
    
    # 1. åˆ†æå½“å‰é—®é¢˜
    analyze_current_chunking_bug()
    
    # 2. å¤‡ä»½å½“å‰æ•°æ®åº“
    backup_current_database()
    
    # 3. æµ‹è¯•æ”¹è¿›ç®—æ³•
    test_improved_chunking()
    
    # 4. æ¸…ç†æœ‰é—®é¢˜çš„æ•°æ®åº“
    clear_problematic_database()
    
    # 5. é‡å»ºå‘é‡æ•°æ®åº“
    if rebuild_with_improved_config():
        # 6. éªŒè¯ä¿®å¤æ•ˆæœ
        if verify_fix():
            print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼")
            print("\nğŸ“‹ åç»­æ­¥éª¤:")
            print("1. è¿è¡Œ python test_retrieval_quality.py æµ‹è¯•æ£€ç´¢è´¨é‡")
            print("2. è¿è¡Œ python main_improved.py è¿›è¡Œå®Œæ•´æµ‹è¯•")
            print("3. æ£€æŸ¥ç³»ç»Ÿåˆ†æ•°æ˜¯å¦æœ‰æ˜¾è‘—æå‡")
        else:
            print("\nâš ï¸ ä¿®å¤ä¸å®Œå…¨ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´å‚æ•°")
    else:
        print("\nâŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 