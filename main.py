"""
é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿä¸»ç¨‹åº
"""

import os
import json
import argparse
import time
from pathlib import Path
from typing import List, Dict, Any

import pandas as pd
from tqdm import tqdm

from config import Config
from rag_engine import RAGEngine
from resume_processor import ResumeProcessor  # å¯¼å…¥æ–­ç‚¹ç»­ä¼ å¤„ç†å™¨


class FinancialQASystem:
    """é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        self.config = Config
        self.rag_engine = None
        self.results = []
        
    def initialize(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("åˆå§‹åŒ–é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ...")
        
        # éªŒè¯è·¯å¾„
        if not self.config.validate_paths():
            print("è·¯å¾„éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return False
            
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.config.create_dirs()
        
        # åˆå§‹åŒ–RAGå¼•æ“
        print("åˆå§‹åŒ–RAGå¼•æ“...")
        self.rag_engine = RAGEngine()
        
        print("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return True
    
    def build_knowledge_base(self, force_rebuild: bool = False):
        """æ„å»ºçŸ¥è¯†åº“"""
        print("æ„å»ºçŸ¥è¯†åº“...")
        
        if self.rag_engine is None:
            print("è¯·å…ˆåˆå§‹åŒ–ç³»ç»Ÿ")
            return False
            
        try:
            self.rag_engine.build_index(force_rebuild=force_rebuild)
            print("çŸ¥è¯†åº“æ„å»ºå®Œæˆ")
            return True
        except Exception as e:
            print(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            return False
    
    def load_test_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½æµ‹è¯•æ•°æ® - æ”¯æŒJSONLæ ¼å¼"""
        print(f"åŠ è½½æµ‹è¯•æ•°æ®: {self.config.TEST_DATA_PATH}")
        
        test_path = Path(self.config.TEST_DATA_PATH)
        if not test_path.exists():
            print(f"æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.config.TEST_DATA_PATH}")
            return []
            
        try:
            # é¦–å…ˆå°è¯•æ ‡å‡†JSONæ ¼å¼
            with open(test_path, 'r', encoding='utf-8') as f:
                try:
                    data = json.load(f)
                    if isinstance(data, list):
                        questions = data
                    else:
                        questions = [data]
                    print(f"âœ… ä½¿ç”¨æ ‡å‡†JSONæ ¼å¼æˆåŠŸåŠ è½½ {len(questions)} ä¸ªé—®é¢˜")
                    return questions
                except json.JSONDecodeError:
                    print("æ ‡å‡†JSONæ ¼å¼è§£æå¤±è´¥ï¼Œå°è¯•JSONLæ ¼å¼...")
                    
            # å°è¯•JSONLæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
            questions = []
            with open(test_path, 'r', encoding='utf-8') as f:
                for line_no, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:  # è·³è¿‡ç©ºè¡Œ
                        continue
                        
                    try:
                        question_data = json.loads(line)
                        questions.append(question_data)
                    except json.JSONDecodeError as e:
                        print(f"è­¦å‘Šï¼šè§£æç¬¬{line_no}è¡Œæ—¶å‡ºé”™: {e}")
                        print(f"é—®é¢˜è¡Œå†…å®¹: {line[:100]}...")
                        continue
                        
            if questions:
                print(f"âœ… ä½¿ç”¨JSONLæ ¼å¼æˆåŠŸåŠ è½½ {len(questions)} ä¸ªé—®é¢˜")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                choice_count = sum(1 for q in questions if q.get('category') == 'é€‰æ‹©é¢˜')
                qa_count = sum(1 for q in questions if q.get('category') == 'é—®ç­”é¢˜')
                print(f"   é€‰æ‹©é¢˜: {choice_count} é“")
                print(f"   é—®ç­”é¢˜: {qa_count} é“")
                
                return questions
            else:
                print("âŒ JSONLæ ¼å¼è§£æä¹Ÿå¤±è´¥äº†")
                return []
                
        except Exception as e:
            print(f"åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return []
    
    def process_question(self, question_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªé—®é¢˜"""
        question_id = question_data.get('id', 'unknown')
        category = question_data.get('category', 'é—®ç­”é¢˜')
        question = question_data.get('question', '')
        content = question_data.get('content', '')
        
        print(f"\nå¤„ç†é—®é¢˜ ID: {question_id}")
        print(f"ç±»åˆ«: {category}")
        print(f"é—®é¢˜: {question}")
        
        # æ„å»ºå®Œæ•´é—®é¢˜ï¼ˆå¯¹äºé€‰æ‹©é¢˜ï¼ŒåŒ…å«é€‰é¡¹ï¼‰
        if category == "é€‰æ‹©é¢˜" and content:
            full_question = f"{question}\n{content}"
        else:
            full_question = question
            
        # è°ƒç”¨RAGå¼•æ“å›ç­”é—®é¢˜
        try:
            result = self.rag_engine.answer_question(full_question, category)
            
            # æ•´ç†ç»“æœ
            processed_result = {
                "id": question_id,
                "category": category,
                "question": question,
                "content": content,
                "answer": result.get("answer", ""),
                "context_used": result.get("context_used", ""),
                "num_sources": result.get("num_sources", 0),
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # å¦‚æœæœ‰é”™è¯¯ï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
            if "error" in result:
                processed_result["error"] = result["error"]
                
            return processed_result
            
        except Exception as e:
            print(f"å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "id": question_id,
                "category": category,
                "question": question,
                "content": content,
                "answer": f"å¤„ç†å¤±è´¥: {e}",
                "error": str(e),
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
    
    def process_batch(self, questions: List[Dict[str, Any]], start_idx: int = 0, end_idx: int = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†é—®é¢˜"""
        if end_idx is None:
            end_idx = len(questions)
            
        print(f"å¼€å§‹æ‰¹é‡å¤„ç†é—®é¢˜ {start_idx} åˆ° {end_idx}")
        
        batch_results = []
        for i in tqdm(range(start_idx, min(end_idx, len(questions))), desc="å¤„ç†é—®é¢˜"):
            question_data = questions[i]
            result = self.process_question(question_data)
            batch_results.append(result)
            
            # å®šæœŸæ¸…ç†GPUç¼“å­˜
            if (i + 1) % 5 == 0:
                self.rag_engine.cleanup()
                
        return batch_results
    
    def save_results(self, results: List[Dict[str, Any]], output_file: str = None, generate_competition_format: bool = False):
        """ä¿å­˜ç»“æœ"""
        if output_file is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = f"{self.config.OUTPUT_DIR}/results_{timestamp}.json"
            
        output_path = Path(output_file)
        output_path.parent.mkdir(exist_ok=True)
        
        try:
            # ä¿å­˜å®Œæ•´ç»“æœï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
                
            print(f"å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
            # åªæœ‰åœ¨æŒ‡å®šæ—¶æ‰ç”Ÿæˆæ¯”èµ›è¦æ±‚çš„result.jsonæ–‡ä»¶
            if generate_competition_format:
                self.save_competition_format(results)
            
            # åŒæ—¶ä¿å­˜ä¸ºCSVæ ¼å¼ä»¥ä¾¿æŸ¥çœ‹
            csv_file = output_path.with_suffix('.csv')
            df = pd.DataFrame(results)
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"ç»“æœCSVæ–‡ä»¶å·²ä¿å­˜åˆ°: {csv_file}")
            
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def save_competition_format(self, results: List[Dict[str, Any]]):
        """ä¿å­˜ç¬¦åˆæ¯”èµ›è¦æ±‚çš„result.jsonæ–‡ä»¶"""
        print("\nğŸ¯ ç”Ÿæˆæ¯”èµ›æäº¤æ ¼å¼æ–‡ä»¶...")
        
        result_file = "result.json"
        
        try:
            with open(result_file, 'w', encoding='utf-8') as f:
                for result in results:
                    # æå–åŸºæœ¬ä¿¡æ¯
                    question_id = result.get('id')
                    category = result.get('category', 'é—®ç­”é¢˜')
                    answer = result.get('answer', '')
                    
                    # å¤„ç†ç­”æ¡ˆæ ¼å¼
                    if category == 'é€‰æ‹©é¢˜':
                        # ä»ç­”æ¡ˆä¸­æå–é€‰é¡¹ï¼ˆAã€Bã€Cã€Dç­‰ï¼‰
                        processed_answer = self.extract_choice_answer(answer)
                    else:
                        # é—®ç­”é¢˜ç›´æ¥ä½¿ç”¨æ–‡æœ¬ç­”æ¡ˆ
                        processed_answer = answer.strip()
                    
                    # æ„å»ºæ¯”èµ›æ ¼å¼çš„JSONå¯¹è±¡
                    competition_result = {
                        "id": question_id,
                        "answer": processed_answer
                    }
                    
                    # å†™å…¥æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
                    json.dump(competition_result, f, ensure_ascii=False)
                    f.write('\n')
            
            print(f"âœ… æ¯”èµ›æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {result_file}")
            
            # éªŒè¯æ–‡ä»¶æ ¼å¼
            self.validate_result_file(result_file)
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶å¤±è´¥: {e}")
    
    def extract_choice_answer(self, answer_text: str) -> List[str]:
        """ä»å›ç­”ä¸­æå–é€‰æ‹©é¢˜ç­”æ¡ˆ - æ”¹è¿›ç‰ˆ"""
        import re
        
        # ğŸ¯ æ”¹è¿›çš„é€‰æ‹©é¢˜ç­”æ¡ˆæ¨¡å¼ï¼Œä¼˜å…ˆçº§ä»é«˜åˆ°ä½
        patterns = [
            # 1. æ˜ç¡®çš„ç­”æ¡ˆå£°æ˜
            r'æ­£ç¡®ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]\s*([A-D])',
            r'ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]\s*([A-D])',
            r'é€‰æ‹©\s*([A-D])',
            r'åº”è¯¥é€‰æ‹©?\s*([A-D])',
            r'ç­”æ¡ˆåº”è¯¥[æ˜¯ä¸º]?\s*([A-D])',
            
            # 2. åˆ†æç»“è®º
            r'å› æ­¤[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            r'æ‰€ä»¥[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            r'ç»¼ä¸Šæ‰€è¿°[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            r'ç»¼åˆåˆ†æ[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            
            # 3. é€‰é¡¹åˆ†æ
            r'é€‰é¡¹\s*([A-D])\s*[æ˜¯ä¸º]?æ­£ç¡®',
            r'([A-D])\s*é€‰é¡¹[æ˜¯ä¸º]?æ­£ç¡®',
            r'([A-D])\s*æ˜¯æ­£ç¡®çš„',
            r'([A-D])\s*æ­£ç¡®',
            
            # 4. æ ¼å¼åŒ–ç­”æ¡ˆ
            r'[é€‰ç­”]\s*([A-D])',
            r'ç­”æ¡ˆ[:ï¼š]\s*([A-D])',
            r'^([A-D])[.ã€ï¼Œ]',  # ä»¥é€‰é¡¹å¼€å¤´
            
            # 5. åœ¨å¥å­ä¸­çš„é€‰é¡¹
            r'\b([A-D])\b.*?æ­£ç¡®',
            r'é€‰æ‹©.*?([A-D])',
        ]
        
        # å…ˆå°è¯•åœ¨å®Œæ•´æ–‡æœ¬ä¸­æŸ¥æ‰¾
        answer_text_clean = answer_text.strip()
        answer_text_upper = answer_text_clean.upper()
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•åŒ¹é…
        for i, pattern in enumerate(patterns):
            matches = re.findall(pattern, answer_text_upper)
            if matches:
                choice = matches[0].strip()
                if choice in ['A', 'B', 'C', 'D']:
                    print(f"âœ… æå–é€‰æ‹©é¢˜ç­”æ¡ˆ: {choice} (æ¨¡å¼{i+1})")
                    return [choice]
        
        # ğŸ¯ æ”¹è¿›ï¼šæ£€æŸ¥æœ€åä¸€å¥è¯ä¸­çš„é€‰é¡¹
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', answer_text_clean)
        for sentence in reversed(sentences):  # ä»æœ€åä¸€å¥å¼€å§‹
            if sentence.strip():
                sentence_upper = sentence.upper()
                for pattern in patterns[:8]:  # ä½¿ç”¨å‰8ä¸ªé«˜ä¼˜å…ˆçº§æ¨¡å¼
                    matches = re.findall(pattern, sentence_upper)
                    if matches:
                        choice = matches[0].strip()
                        if choice in ['A', 'B', 'C', 'D']:
                            print(f"âœ… ä»å¥å­ä¸­æå–é€‰æ‹©é¢˜ç­”æ¡ˆ: {choice}")
                            return [choice]
        
        # ğŸ¯ æ”¹è¿›ï¼šæŸ¥æ‰¾å•ç‹¬å‡ºç°çš„é€‰é¡¹
        isolated_choices = re.findall(r'\b([A-D])\b', answer_text_upper)
        if isolated_choices:
            # ç»Ÿè®¡æ¯ä¸ªé€‰é¡¹å‡ºç°çš„æ¬¡æ•°
            choice_counts = {}
            for choice in isolated_choices:
                choice_counts[choice] = choice_counts.get(choice, 0) + 1
            
            # é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„ï¼Œå¦‚æœå¹³å±€åˆ™é€‰æ‹©æœ€åå‡ºç°çš„
            if choice_counts:
                max_count = max(choice_counts.values())
                frequent_choices = [c for c, count in choice_counts.items() if count == max_count]
                
                # åœ¨é¢‘ç¹é€‰é¡¹ä¸­é€‰æ‹©æœ€åå‡ºç°çš„
                for choice in reversed(isolated_choices):
                    if choice in frequent_choices:
                        print(f"âœ… åŸºäºé¢‘ç‡æå–é€‰æ‹©é¢˜ç­”æ¡ˆ: {choice}")
                        return [choice]
        
        # ğŸ¯ æœ€åå°è¯•ï¼šåŸºäºå…³é”®è¯æ¨æµ‹
        answer_lower = answer_text.lower()
        if any(word in answer_lower for word in ['ç¬¬ä¸€', 'é¦–å…ˆ', 'æœ€åˆ']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: A")
            return ["A"]
        elif any(word in answer_lower for word in ['ç¬¬äºŒ', 'å…¶æ¬¡', 'å¦å¤–']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: B")
            return ["B"]
        elif any(word in answer_lower for word in ['ç¬¬ä¸‰', 'å†è€…', 'æ­¤å¤–']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: C")
            return ["C"]
        elif any(word in answer_lower for word in ['ç¬¬å››', 'æœ€å', 'æœ€ç»ˆ']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: D")
            return ["D"]
        
        # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤ç­”æ¡ˆ
        print(f"âš ï¸ æ— æ³•ä»ç­”æ¡ˆä¸­æå–é€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤ç­”æ¡ˆA")
        print(f"åŸæ–‡: {answer_text[:200]}...")
        return ["A"]  # é»˜è®¤é€‰æ‹©A
    
    def validate_result_file(self, result_file: str):
        """éªŒè¯ç»“æœæ–‡ä»¶æ ¼å¼"""
        print("ğŸ” éªŒè¯ç»“æœæ–‡ä»¶æ ¼å¼...")
        
        try:
            choice_count = 0
            qa_count = 0
            
            with open(result_file, 'r', encoding='utf-8') as f:
                for line_no, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        data = json.loads(line)
                        
                        # æ£€æŸ¥å¿…éœ€å­—æ®µ
                        if 'id' not in data or 'answer' not in data:
                            print(f"âŒ ç¬¬{line_no}è¡Œç¼ºå°‘å¿…éœ€å­—æ®µ: {line}")
                            continue
                        
                        # ç»Ÿè®¡ç­”æ¡ˆç±»å‹
                        answer = data['answer']
                        if isinstance(answer, list):
                            choice_count += 1
                        else:
                            qa_count += 1
                            
                    except json.JSONDecodeError as e:
                        print(f"âŒ ç¬¬{line_no}è¡ŒJSONæ ¼å¼é”™è¯¯: {e}")
            
            print(f"âœ… æ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
            print(f"   é€‰æ‹©é¢˜: {choice_count} é“")
            print(f"   é—®ç­”é¢˜: {qa_count} é“")
            print(f"   æ€»è®¡: {choice_count + qa_count} é“")
            
            # æ˜¾ç¤ºå‰å‡ è¡Œç¤ºä¾‹
            print("\nğŸ“ æ–‡ä»¶å†…å®¹ç¤ºä¾‹:")
            with open(result_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= 3:  # åªæ˜¾ç¤ºå‰3è¡Œ
                        break
                    print(f"   {line.strip()}")
                        
        except Exception as e:
            print(f"âŒ éªŒè¯æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def run_test(self, force_rebuild: bool = False, batch_size: int = None, start_idx: int = 0, end_idx: int = None, no_resume: bool = False):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("å¼€å§‹è¿è¡Œé‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”æµ‹è¯•")
        
        # åˆå§‹åŒ–æ–­ç‚¹ç»­ä¼ å¤„ç†å™¨
        resume_processor = ResumeProcessor()
        
        # æ¸…ç†æ—§çš„ä¸­é—´æ–‡ä»¶
        self.cleanup_intermediate_files()
        
        # ç”Ÿæˆæœ¬æ¬¡è¿è¡Œçš„å”¯ä¸€æ ‡è¯†
        run_timestamp = time.strftime("%Y%m%d_%H%M%S")
        print(f"ğŸ·ï¸ æœ¬æ¬¡è¿è¡Œæ ‡è¯†: {run_timestamp}")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        if not self.initialize():
            return False
            
        # æ„å»ºçŸ¥è¯†åº“
        if not self.build_knowledge_base(force_rebuild=force_rebuild):
            return False
            
        # åŠ è½½æµ‹è¯•æ•°æ®
        questions = self.load_test_data()
        if not questions:
            print("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•æ•°æ®")
            return False
            
        # è®¾ç½®æ‰¹å¤„ç†å¤§å°
        if batch_size is None:
            batch_size = self.config.BATCH_SIZE
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šæ¬¡çš„æ–­ç‚¹
        checkpoint_start_idx = None
        checkpoint_batch_size = None
        checkpoint_results = None
        
        if not no_resume and resume_processor.has_checkpoint():
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­ä¸Šæ¬¡çš„å¤„ç†
            print("\nğŸ”„ æ£€æµ‹åˆ°ä¸Šæ¬¡å¤„ç†çš„æ–­ç‚¹")
            choice = input("æ˜¯å¦ç»§ç»­ä¸Šæ¬¡çš„å¤„ç†? (y/nï¼Œé»˜è®¤y): ").strip().lower()
            
            if choice != 'n':
                checkpoint_start_idx, checkpoint_batch_size, checkpoint_results = resume_processor.load_checkpoint()
                
                if checkpoint_start_idx is not None:
                    start_idx = checkpoint_start_idx
                    print(f"ğŸ”„ å°†ä»ç´¢å¼• {start_idx} ç»§ç»­å¤„ç†")
                    
                    if checkpoint_batch_size is not None:
                        batch_size = checkpoint_batch_size
                        print(f"ğŸ”„ ä½¿ç”¨ä¸Šæ¬¡çš„æ‰¹å¤„ç†å¤§å°: {batch_size}")
                    
                    if checkpoint_results:
                        print(f"ğŸ”„ å·²åŠ è½½ä¸Šæ¬¡çš„å¤„ç†ç»“æœ: {len(checkpoint_results)} ä¸ªé—®é¢˜")
                        all_results = checkpoint_results
                    else:
                        all_results = []
                else:
                    all_results = []
            else:
                # ç”¨æˆ·é€‰æ‹©ä»å¤´å¼€å§‹ï¼Œæ¸…é™¤æ£€æŸ¥ç‚¹
                resume_processor.clear_checkpoint()
                all_results = []
        else:
            # å¼ºåˆ¶ä»å¤´å¼€å§‹ï¼Œæˆ–è€…æ²¡æœ‰æ£€æŸ¥ç‚¹
            if no_resume and resume_processor.has_checkpoint():
                print("ğŸ§¹ æ ¹æ®å‚æ•°è®¾ç½®ï¼Œå¿½ç•¥æ–­ç‚¹ï¼Œä»å¤´å¼€å§‹å¤„ç†")
                resume_processor.clear_checkpoint()
            all_results = []
        
        # è®¾ç½®å¤„ç†èŒƒå›´
        if end_idx is None or end_idx > len(questions):
            end_idx = len(questions)
            
        print(f"å°†å¤„ç† {end_idx - start_idx} ä¸ªé—®é¢˜ (ç´¢å¼• {start_idx} åˆ° {end_idx - 1})")
        
        # åˆ†æ‰¹å¤„ç†
        try:
            for batch_start in range(start_idx, end_idx, batch_size):
                batch_end = min(batch_start + batch_size, end_idx)
                
                print(f"\nå¤„ç†æ‰¹æ¬¡ {batch_start}-{batch_end-1}")
                batch_results = self.process_batch(questions, batch_start, batch_end)
                all_results.extend(batch_results)
                
                # ä¿å­˜ä¸­é—´ç»“æœï¼ˆä¸ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶ï¼‰
                intermediate_file = f"{self.config.OUTPUT_DIR}/batch_results_{batch_start}_{batch_end-1}_{run_timestamp}.json"
                self.save_results(batch_results, intermediate_file, generate_competition_format=False)
                
                # ä¿å­˜æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹
                resume_processor.save_checkpoint(batch_end, end_idx, batch_size, all_results)
                
                print(f"æ‰¹æ¬¡ {batch_start}-{batch_end-1} å¤„ç†å®Œæˆ")
                
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
            print(f"ğŸ’¾ å·²å¤„ç†ç»“æœå°†ä¿å­˜åœ¨æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹ä¸­")
            resume_processor.save_checkpoint(batch_start, end_idx, batch_size, all_results)
            return False
        except Exception as e:
            print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            print(f"ğŸ’¾ å·²å¤„ç†ç»“æœå°†ä¿å­˜åœ¨æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹ä¸­")
            resume_processor.save_checkpoint(batch_start, end_idx, batch_size, all_results)
            return False
        
        # ä¿å­˜æœ€ç»ˆç»“æœï¼ˆç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶ï¼‰
        print(f"\nğŸ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆç»“æœ...")
        final_result_file = f"{self.config.OUTPUT_DIR}/final_results_{run_timestamp}.json"
        competition_result_file = f"result_{run_timestamp}.json"
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        self.save_results(all_results, final_result_file, generate_competition_format=False)
        
        # ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶
        self.save_competition_format_with_filename(all_results, competition_result_file)
        
        # åŒæ—¶ç”Ÿæˆé»˜è®¤åç§°çš„result.jsonï¼ˆè¦†ç›–æ—§ç‰ˆæœ¬ï¼‰
        self.save_competition_format_with_filename(all_results, "result.json")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_statistics(all_results)
        
        print(f"\nğŸ¯ æ¯”èµ›æ–‡ä»¶å·²ç”Ÿæˆ:")
        print(f"   - {competition_result_file} (å¸¦æ—¶é—´æˆ³)")
        print(f"   - result.json (é»˜è®¤æ–‡ä»¶)")
        print("æµ‹è¯•å®Œæˆï¼")
        
        # æ¸…é™¤æ£€æŸ¥ç‚¹ï¼ˆæˆåŠŸå®Œæˆåï¼‰
        resume_processor.clear_checkpoint()
        
        return True
    
    def cleanup_intermediate_files(self):
        """æ¸…ç†æ—§çš„ä¸­é—´æ–‡ä»¶"""
        print("ğŸ§¹ æ¸…ç†æ—§çš„ä¸­é—´æ–‡ä»¶...")
        
        output_dir = Path(self.config.OUTPUT_DIR)
        if not output_dir.exists():
            return
            
        # æ¸…ç†æ‰¹æ¬¡ç»“æœæ–‡ä»¶
        batch_files = list(output_dir.glob("batch_results_*.json"))
        for file in batch_files:
            try:
                file.unlink()
                print(f"   âœ… åˆ é™¤: {file.name}")
            except Exception as e:
                print(f"   âŒ åˆ é™¤å¤±è´¥ {file.name}: {e}")
        
        if batch_files:
            print(f"æ¸…ç†äº† {len(batch_files)} ä¸ªä¸­é—´æ–‡ä»¶")
        else:
            print("æ²¡æœ‰éœ€è¦æ¸…ç†çš„ä¸­é—´æ–‡ä»¶")

    def save_competition_format_with_filename(self, results: List[Dict[str, Any]], filename: str):
        """ä¿å­˜æ¯”èµ›æ ¼å¼æ–‡ä»¶åˆ°æŒ‡å®šæ–‡ä»¶å"""
        print(f"\nğŸ¯ ç”Ÿæˆæ¯”èµ›æäº¤æ ¼å¼æ–‡ä»¶: {filename}")
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                for result in results:
                    # æå–åŸºæœ¬ä¿¡æ¯
                    question_id = result.get('id')
                    category = result.get('category', 'é—®ç­”é¢˜')
                    answer = result.get('answer', '')
                    
                    # å¤„ç†ç­”æ¡ˆæ ¼å¼
                    if category == 'é€‰æ‹©é¢˜':
                        # ä»ç­”æ¡ˆä¸­æå–é€‰é¡¹ï¼ˆAã€Bã€Cã€Dç­‰ï¼‰
                        processed_answer = self.extract_choice_answer(answer)
                    else:
                        # é—®ç­”é¢˜ç›´æ¥ä½¿ç”¨æ–‡æœ¬ç­”æ¡ˆ
                        processed_answer = answer.strip()
                    
                    # æ„å»ºæ¯”èµ›æ ¼å¼çš„JSONå¯¹è±¡
                    competition_result = {
                        "id": question_id,
                        "answer": processed_answer
                    }
                    
                    # å†™å…¥æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
                    json.dump(competition_result, f, ensure_ascii=False)
                    f.write('\n')
            
            print(f"âœ… æ¯”èµ›æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {filename}")
            
            # éªŒè¯æ–‡ä»¶æ ¼å¼
            self.validate_result_file(filename)
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶å¤±è´¥: {e}")
    
    def print_statistics(self, results: List[Dict[str, Any]]):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯")
        print("="*50)
        
        total_questions = len(results)
        choice_questions = sum(1 for r in results if r.get('category') == 'é€‰æ‹©é¢˜')
        qa_questions = sum(1 for r in results if r.get('category') == 'é—®ç­”é¢˜')
        error_count = sum(1 for r in results if 'error' in r)
        
        print(f"æ€»é—®é¢˜æ•°: {total_questions}")
        print(f"é€‰æ‹©é¢˜æ•°: {choice_questions}")
        print(f"é—®ç­”é¢˜æ•°: {qa_questions}")
        print(f"å¤„ç†å¤±è´¥æ•°: {error_count}")
        print(f"æˆåŠŸç‡: {((total_questions - error_count) / total_questions * 100):.2f}%")
        
        # ç»Ÿè®¡å¹³å‡æ£€ç´¢æºæ•°é‡
        avg_sources = sum(r.get('num_sources', 0) for r in results if 'error' not in r) / max(1, total_questions - error_count)
        print(f"å¹³å‡æ£€ç´¢æºæ•°é‡: {avg_sources:.2f}")
        
        # æ˜¾ç¤ºå‘é‡æ•°æ®åº“ç»Ÿè®¡
        if self.rag_engine:
            vector_stats = self.rag_engine.get_vector_db_stats()
            print(f"\nå‘é‡æ•°æ®åº“ç»Ÿè®¡:")
            for key, value in vector_stats.items():
                print(f"  {key}: {value}")
    
    def show_vector_db_info(self):
        """æ˜¾ç¤ºå‘é‡æ•°æ®åº“ä¿¡æ¯"""
        if not self.rag_engine:
            print("RAGå¼•æ“æœªåˆå§‹åŒ–")
            return
            
        stats = self.rag_engine.get_vector_db_stats()
        print("\n" + "="*50)
        print("å‘é‡æ•°æ®åº“è¯¦ç»†ä¿¡æ¯")
        print("="*50)
        
        for key, value in stats.items():
            print(f"{key}: {value}")
    
    def rebuild_vector_database(self):
        """é‡å»ºå‘é‡æ•°æ®åº“"""
        print("å¼€å§‹é‡å»ºå‘é‡æ•°æ®åº“...")
        
        if not self.initialize():
            return False
            
        try:
            self.rag_engine.rebuild_vector_db()
            print("å‘é‡æ•°æ®åº“é‡å»ºå®Œæˆ")
            self.show_vector_db_info()
            return True
        except Exception as e:
            print(f"é‡å»ºå‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    parser.add_argument("--force-rebuild", action="store_true", help="å¼ºåˆ¶é‡å»ºç´¢å¼•")
    parser.add_argument("--batch-size", type=int, default=10, help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--start-idx", type=int, default=0, help="å¼€å§‹ç´¢å¼•")
    parser.add_argument("--end-idx", type=int, help="ç»“æŸç´¢å¼•")
    parser.add_argument("--interactive", action="store_true", help="äº¤äº’å¼é—®ç­”æ¨¡å¼")
    parser.add_argument("--vector-info", action="store_true", help="æ˜¾ç¤ºå‘é‡æ•°æ®åº“ä¿¡æ¯")
    parser.add_argument("--rebuild-vector", action="store_true", help="é‡å»ºå‘é‡æ•°æ®åº“")
    # æ–­ç‚¹ç»­ä¼ ç›¸å…³å‚æ•°
    parser.add_argument("--no-resume", action="store_true", help="ä¸ä½¿ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œä»å¤´å¼€å§‹å¤„ç†")
    parser.add_argument("--checkpoint-info", action="store_true", help="æ˜¾ç¤ºå½“å‰æ£€æŸ¥ç‚¹ä¿¡æ¯")
    parser.add_argument("--checkpoint-clear", action="store_true", help="æ¸…é™¤å½“å‰æ£€æŸ¥ç‚¹")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    qa_system = FinancialQASystem()
    
    # å¤„ç†æ–­ç‚¹ç»­ä¼ ç›¸å…³å‘½ä»¤
    if args.checkpoint_info or args.checkpoint_clear:
        from resume_processor import ResumeProcessor
        resume = ResumeProcessor()
        
        if args.checkpoint_info:
            # æ˜¾ç¤ºæ£€æŸ¥ç‚¹ä¿¡æ¯
            if resume.has_checkpoint():
                with open(resume.checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint_data = json.load(f)
                
                print("\n" + "="*50)
                print("ğŸ“Š æ£€æŸ¥ç‚¹ä¿¡æ¯")
                print("="*50)
                
                print(f"ğŸ•’ ä¿å­˜æ—¶é—´: {checkpoint_data.get('time_str', 'æœªçŸ¥')}")
                print(f"ğŸ“ˆ è¿›åº¦: {checkpoint_data.get('current_idx', 0)}/{checkpoint_data.get('total', 0)} "
                      f"({checkpoint_data.get('completed_percentage', 0)}%)")
                print(f"ğŸ“¦ æ‰¹å¤„ç†å¤§å°: {checkpoint_data.get('batch_size', 0)}")
            else:
                print("ğŸ“ æ²¡æœ‰æ£€æŸ¥ç‚¹ä¿¡æ¯")
        
        if args.checkpoint_clear:
            # æ¸…é™¤æ£€æŸ¥ç‚¹
            if resume.has_checkpoint():
                if resume.clear_checkpoint():
                    print("âœ… æ£€æŸ¥ç‚¹å·²æ¸…é™¤")
            else:
                print("ğŸ“ æ²¡æœ‰æ£€æŸ¥ç‚¹éœ€è¦æ¸…é™¤")
        
        # å¦‚æœåªæ˜¯æŸ¥çœ‹æˆ–æ¸…é™¤æ£€æŸ¥ç‚¹ï¼Œä¸æ‰§è¡Œå…¶ä»–æ“ä½œ
        if not any([args.vector_info, args.rebuild_vector, args.interactive]):
            return
    
    if args.vector_info:
        # æ˜¾ç¤ºå‘é‡æ•°æ®åº“ä¿¡æ¯
        qa_system.initialize()
        qa_system.show_vector_db_info()
        return
        
    if args.rebuild_vector:
        # é‡å»ºå‘é‡æ•°æ®åº“
        qa_system.rebuild_vector_database()
        return
    
    if args.interactive:
        # äº¤äº’å¼æ¨¡å¼
        print("è¿›å…¥äº¤äº’å¼é—®ç­”æ¨¡å¼")
        if not qa_system.initialize():
            return
            
        if not qa_system.build_knowledge_base(force_rebuild=args.force_rebuild):
            return
            
        print("ç³»ç»Ÿå‡†å¤‡å°±ç»ªï¼Œè¾“å…¥ 'quit' é€€å‡ºï¼Œ'info' æŸ¥çœ‹å‘é‡æ•°æ®åº“ä¿¡æ¯")
        
        while True:
            user_input = input("\nè¯·è¾“å…¥é—®é¢˜: ").strip()
            if user_input.lower() == 'quit':
                break
            elif user_input.lower() == 'info':
                qa_system.show_vector_db_info()
                continue
                
            if not user_input:
                continue
                
            result = qa_system.rag_engine.answer_question(user_input, "é—®ç­”é¢˜")
            print(f"\nç­”æ¡ˆ: {result.get('answer', 'æ— æ³•ç”Ÿæˆç­”æ¡ˆ')}")
            
    else:
        # æ‰¹é‡æµ‹è¯•æ¨¡å¼
        qa_system.run_test(
            force_rebuild=args.force_rebuild,
            batch_size=args.batch_size,
            start_idx=args.start_idx,
            end_idx=args.end_idx,
            no_resume=args.no_resume
        )


if __name__ == "__main__":
    main() 