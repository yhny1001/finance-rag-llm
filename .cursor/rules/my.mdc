---
description: coding
globs: 
alwaysApply: false
---
你是一个资深的llm专家,擅长编写rag+llm的本地项目。
擅长python


开发要求 
    金融监管制度智能问答
    基于大模型的文档问答，根据输入的问题（如“个人理财产品的销售需满足哪些监管要求？”），基于给定的金融文档库，生成准确、合规的答案。题型包含不定项选择题和问答题。
    {"id":12,"category":"选择题","question":"城商行内审部门负责人任职后需在多少日内备案？","content":"A. 3个工作日\nB. 5个工作日\nC. 10个工作日\nD. 30个工作日"}
    {"id":13,"category":"问答题","question":"简述商业银行资本充足率的最低监管要求指标及各自数值。","content":null}
    
    一致性：有任何更改，必须保证主程序、readme的一致性，不过多生成文件
    代码清理：替换新的解决方案后，要检查之前的代码是否还有使用，没有用就删除掉
    错误检查：每次代码修改后，必须检查开发工具测试报告错误并立即解决
    服务器运行:所有的代码是在服务器上运行的，对于大模型相关的文件不需要下载或者本地运行，可以提示user测试代码及如何运行，由user进行调试
    零错误提交：禁止提交包含编译错误的代码到代码库。
    本地运行:除需pip安装依赖外，所有的模型均本地运行
    定期清理：可以分批生成，节约缓存
    合规原则：索引数组绝不能越界,必须节约cuda缓存
    命中率原则：命中率不可过低
    可视性原则:要有完整的print日志，以便于debug

开发规范
    使用llamaIndex框架
    rag方法
    python作为开发语言
    包含所有的依赖库和包的名称
    暂时不需要前端界面，只需要主运行程序
开发配置
    modelscope的服务器环境：8核 32GB 显存24G
    预装 ModelScope Library

项目结构
    ./根目录
├── config.py                 # 配置文件：系统参数配置
├── ******.py                 # 主程序启动：命令行界面与主流程
├── ******.py                 #  RAG模型核心实现：包含嵌入、检索、生成功能
├── requirements.txt          # 依赖项列表，在开发
├── README.md                 # 开发文档说明
|——需求文档.md                 #需求文档说明
├── 赛题制度文档/              #内含800多个制度文档 
├── 数据集A/testA.json        # 为需处理答题的题目
………………

注意:
要适配modelscope的服务器环境
千问2.5-7B的模型的路径位置在
/mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-7B-Instruct
embeddeding模型的路径位置在 
/mnt/workspace/.cache/modelscope/models/Jerry0/m3e-base

整体rag的运行思路
1、通过调用大模型和rag模型，对于文档进行切片，保证其正常启动
2、通过数据集，遍历所有的题目，然后分组运行，
3、通过rag query 调用查询，不同的题目，从数据库内容查询到多个内容后，判断一致率是否引用
4、一并将切片内容和问题，直接全部输入给大模型，给出答案先。
5、给出答案后，简答题直接给出回答，选择/判断题等，要进行判断最后给出结果。


