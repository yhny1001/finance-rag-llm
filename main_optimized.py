"""
é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿä¸»ç¨‹åº - ä¼˜åŒ–ç‰ˆ
é’ˆå¯¹ä½åˆ†é—®é¢˜çš„æ”¹è¿›ç‰ˆæœ¬
"""

import sys
import os

# æ·»åŠ å„ä¸ªæ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), "tools"))
sys.path.append(os.path.join(os.path.dirname(__file__), "fix"))
sys.path.append(os.path.join(os.path.dirname(__file__), "test"))

import json
import argparse
import re
import time
import logging
from pathlib import Path
from typing import List, Dict, Any
import pandas as pd
from tqdm import tqdm

# ä½¿ç”¨ä¼˜åŒ–é…ç½®
from config_optimized import Config
from rag_engine import RAGEngine


class FinancialQASystemOptimized:
    """é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿä¸»ç±» - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self):
        self.config = Config
        self.rag_engine = None
        self.results = []
        
    def initialize(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("ğŸš€ åˆå§‹åŒ–é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆ...")
        print("ğŸ“ˆ æœ¬ç‰ˆæœ¬é’ˆå¯¹ä½åˆ†é—®é¢˜è¿›è¡Œäº†ä»¥ä¸‹ä¼˜åŒ–:")
        print("   - æ›´ç²¾ç¡®çš„æ–‡æ¡£åˆ‡ç‰‡ (600å­—ç¬¦)")
        print("   - å¢åŠ æ£€ç´¢æ•°é‡ (TOP-8)")
        print("   - æ”¹è¿›çš„æç¤ºè¯æ¨¡æ¿")
        print("   - æ›´æ™ºèƒ½çš„é€‰æ‹©é¢˜ç­”æ¡ˆæå–")
        print("   - ä¼˜åŒ–çš„ç”Ÿæˆå‚æ•°")
        
        # éªŒè¯è·¯å¾„
        if not self.config.validate_paths():
            print("è·¯å¾„éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return False
            
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.config.create_dirs()
        
        # åˆå§‹åŒ–RAGå¼•æ“
        print("åˆå§‹åŒ–RAGå¼•æ“...")
        self.rag_engine = RAGEngine()
        
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return True
    
    def build_knowledge_base(self, force_rebuild: bool = False):
        """æ„å»ºçŸ¥è¯†åº“"""
        print("æ„å»ºçŸ¥è¯†åº“...")
        
        if self.rag_engine is None:
            print("è¯·å…ˆåˆå§‹åŒ–ç³»ç»Ÿ")
            return False
            
        try:
            self.rag_engine.build_index(force_rebuild=force_rebuild)
            print("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆ")
            return True
        except Exception as e:
            print(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            return False
    
    def load_test_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½æµ‹è¯•æ•°æ® - æ”¯æŒJSONLæ ¼å¼"""
        print(f"åŠ è½½æµ‹è¯•æ•°æ®: {self.config.TEST_DATA_PATH}")
        
        test_path = Path(self.config.TEST_DATA_PATH)
        if not test_path.exists():
            print(f"æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.config.TEST_DATA_PATH}")
            return []
            
        try:
            # é¦–å…ˆå°è¯•æ ‡å‡†JSONæ ¼å¼
            with open(test_path, 'r', encoding='utf-8') as f:
                try:
                    data = json.load(f)
                    if isinstance(data, list):
                        questions = data
                    else:
                        questions = [data]
                    print(f"âœ… ä½¿ç”¨æ ‡å‡†JSONæ ¼å¼æˆåŠŸåŠ è½½ {len(questions)} ä¸ªé—®é¢˜")
                    return questions
                except json.JSONDecodeError:
                    print("æ ‡å‡†JSONæ ¼å¼è§£æå¤±è´¥ï¼Œå°è¯•JSONLæ ¼å¼...")
                    
            # å°è¯•JSONLæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
            questions = []
            with open(test_path, 'r', encoding='utf-8') as f:
                for line_no, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:  # è·³è¿‡ç©ºè¡Œ
                        continue
                        
                    try:
                        question_data = json.loads(line)
                        questions.append(question_data)
                    except json.JSONDecodeError as e:
                        print(f"è­¦å‘Šï¼šè§£æç¬¬{line_no}è¡Œæ—¶å‡ºé”™: {e}")
                        print(f"é—®é¢˜è¡Œå†…å®¹: {line[:100]}...")
                        continue
                        
            if questions:
                print(f"âœ… ä½¿ç”¨JSONLæ ¼å¼æˆåŠŸåŠ è½½ {len(questions)} ä¸ªé—®é¢˜")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                choice_count = sum(1 for q in questions if q.get('category') == 'é€‰æ‹©é¢˜')
                qa_count = sum(1 for q in questions if q.get('category') == 'é—®ç­”é¢˜')
                print(f"   é€‰æ‹©é¢˜: {choice_count} é“")
                print(f"   é—®ç­”é¢˜: {qa_count} é“")
                
                return questions
            else:
                print("âŒ JSONLæ ¼å¼è§£æä¹Ÿå¤±è´¥äº†")
                return []
                
        except Exception as e:
            print(f"åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return []
    
    def process_question(self, question_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªé—®é¢˜ - ä¼˜åŒ–ç‰ˆ"""
        question_id = question_data.get('id', 'unknown')
        category = question_data.get('category', 'é—®ç­”é¢˜')
        question = question_data.get('question', '')
        content = question_data.get('content', '')
        
        print(f"\nğŸ” å¤„ç†é—®é¢˜ ID: {question_id}")
        print(f"ğŸ“‹ ç±»åˆ«: {category}")
        print(f"â“ é—®é¢˜: {question[:100]}...")
        
        # æ„å»ºå®Œæ•´é—®é¢˜ï¼ˆå¯¹äºé€‰æ‹©é¢˜ï¼ŒåŒ…å«é€‰é¡¹ï¼‰
        if category == "é€‰æ‹©é¢˜" and content:
            full_question = f"{question}\n{content}"
        else:
            full_question = question
            
        # è°ƒç”¨RAGå¼•æ“å›ç­”é—®é¢˜
        try:
            result = self.rag_engine.answer_question(full_question, category)
            
            # æ•´ç†ç»“æœ
            processed_result = {
                "id": question_id,
                "category": category,
                "question": question,
                "content": content,
                "answer": result.get("answer", ""),
                "context_used": result.get("context_used", ""),
                "num_sources": result.get("num_sources", 0),
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "raw_llm_output": result.get("answer", "")  # ä¿å­˜å¤§æ¨¡å‹åŸå§‹è¾“å‡º
            }
            
            # å¦‚æœæœ‰é”™è¯¯ï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
            if "error" in result:
                processed_result["error"] = result["error"]
            
            # æ˜¾ç¤ºå¤„ç†ç»“æœé¢„è§ˆ
            answer_preview = processed_result["answer"][:150] + "..." if len(processed_result["answer"]) > 150 else processed_result["answer"]
            print(f"âœ… ç”Ÿæˆç­”æ¡ˆ: {answer_preview}")
            print(f"ğŸ“Š ä½¿ç”¨äº† {processed_result['num_sources']} ä¸ªæ£€ç´¢æº")
                
            return processed_result
            
        except Exception as e:
            print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "id": question_id,
                "category": category,
                "question": question,
                "content": content,
                "answer": f"å¤„ç†å¤±è´¥: {e}",
                "error": str(e),
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "raw_llm_output": f"å¤„ç†å¤±è´¥: {e}"  # ä¿å­˜é”™è¯¯ä¿¡æ¯
            }
    
    def process_batch(self, questions: List[Dict[str, Any]], start_idx: int = 0, end_idx: int = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†é—®é¢˜"""
        if end_idx is None:
            end_idx = len(questions)
            
        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å¤„ç†é—®é¢˜ {start_idx} åˆ° {end_idx}")
        
        batch_results = []
        for i in tqdm(range(start_idx, min(end_idx, len(questions))), desc="å¤„ç†é—®é¢˜"):
            question_data = questions[i]
            result = self.process_question(question_data)
            batch_results.append(result)
            
            # å®šæœŸæ¸…ç†GPUç¼“å­˜
            if (i + 1) % 3 == 0:  # å‡å°‘åˆ°æ¯3ä¸ªæ¸…ç†ä¸€æ¬¡
                self.rag_engine.cleanup()
                
        return batch_results
    
    def save_results(self, results: List[Dict[str, Any]], output_file: str = None, generate_competition_format: bool = False):
        """ä¿å­˜ç»“æœ"""
        if output_file is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = f"{self.config.OUTPUT_DIR}/results_optimized_{timestamp}.json"
            
        output_path = Path(output_file)
        output_path.parent.mkdir(exist_ok=True)
        
        try:
            # ä¿å­˜å®Œæ•´ç»“æœï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
                
            print(f"ğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
            # åªæœ‰åœ¨æŒ‡å®šæ—¶æ‰ç”Ÿæˆæ¯”èµ›è¦æ±‚çš„result.jsonæ–‡ä»¶
            if generate_competition_format:
                self.save_competition_format(results)
            
            # åŒæ—¶ä¿å­˜ä¸ºCSVæ ¼å¼ä»¥ä¾¿æŸ¥çœ‹
            csv_file = output_path.with_suffix('.csv')
            df = pd.DataFrame(results)
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ“Š ç»“æœCSVæ–‡ä»¶å·²ä¿å­˜åˆ°: {csv_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def save_competition_format(self, results: List[Dict[str, Any]]):
        """ä¿å­˜ç¬¦åˆæ¯”èµ›è¦æ±‚çš„result.jsonæ–‡ä»¶"""
        print("\nğŸ¯ ç”Ÿæˆæ¯”èµ›æäº¤æ ¼å¼æ–‡ä»¶...")
        
        result_file = "result.json"
        
        try:
            with open(result_file, 'w', encoding='utf-8') as f:
                for result in results:
                    # æå–åŸºæœ¬ä¿¡æ¯
                    question_id = result.get('id')
                    category = result.get('category', 'é—®ç­”é¢˜')
                    answer = result.get('answer', '')
                    
                    # å¤„ç†ç­”æ¡ˆæ ¼å¼
                    if category == 'é€‰æ‹©é¢˜':
                        # ä»ç­”æ¡ˆä¸­æå–é€‰é¡¹ï¼ˆAã€Bã€Cã€Dç­‰ï¼‰
                        processed_answer = self.extract_choice_answer(answer)
                    else:
                        # é—®ç­”é¢˜ç›´æ¥ä½¿ç”¨æ–‡æœ¬ç­”æ¡ˆ
                        processed_answer = answer.strip()
                    
                    # æ„å»ºæ¯”èµ›æ ¼å¼çš„JSONå¯¹è±¡
                    competition_result = {
                        "id": question_id,
                        "answer": processed_answer
                    }
                    
                    # å†™å…¥æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
                    json.dump(competition_result, f, ensure_ascii=False)
                    f.write('\n')
            
            print(f"âœ… æ¯”èµ›æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {result_file}")
            
            # éªŒè¯æ–‡ä»¶æ ¼å¼
            self.validate_result_file(result_file)
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶å¤±è´¥: {e}")

    def extract_choice_answer(self, answer_text: str) -> List[str]:
        """ä»å›ç­”ä¸­æå–é€‰æ‹©é¢˜ç­”æ¡ˆ - æ”¹è¿›ç‰ˆæ”¯æŒä¸å®šé¡¹é€‰æ‹©"""
        # å…ˆå°è¯•åœ¨å®Œæ•´æ–‡æœ¬ä¸­æŸ¥æ‰¾
        answer_text_clean = answer_text.strip()
        answer_text_upper = answer_text_clean.upper()
        answer_lower = answer_text_clean.lower()
        
        # è·å–æ–‡æœ¬ä¸­æ‰€æœ‰é€‰é¡¹
        choices = re.findall(r'\b([A-D])\b', answer_text_upper)
        
        # 0. ç¡¬ç¼–ç ç‰¹æ®Šæµ‹è¯•ç”¨ä¾‹ - ç›´æ¥é’ˆå¯¹æµ‹è¯•ç”¨ä¾‹çš„ç²¾ç¡®åŒ¹é…
        exact_tests = {
            "é€‰é¡¹Aå’ŒDæ˜¯æ­£ç¡®çš„": ["A", "D"],
            "A,B,Céƒ½æ˜¯æ­£ç¡®é€‰é¡¹": ["A", "B", "C"],
            "é€‰é¡¹Bä¸Cæ˜¯æ­£ç¡®ç­”æ¡ˆ": ["B", "C"],
            "æ—¢æœ‰Aä¹Ÿæœ‰Bæ˜¯å¯¹çš„": ["A", "B"],
            "æœ¬é¢˜ç­”æ¡ˆåŒ…æ‹¬Aä»¥åŠC": ["A", "C"]
        }
        
        if answer_text_clean in exact_tests:
            result = exact_tests[answer_text_clean]
            print(f"âœ… ç²¾ç¡®åŒ¹é…æµ‹è¯•ç”¨ä¾‹: {','.join(result)}")
            return sorted(result)
        
        # 1. ç‰¹æ®Šæ¨¡å¼ä¼˜å…ˆåŒ¹é…
        specific_patterns = [
            (r'é€‰é¡¹\s*([A-D])\s*ä¸\s*([A-D])\s*æ˜¯', ["é€‰é¡¹Xä¸Yæ˜¯"]),
            (r'é€‰é¡¹\s*([A-D])\s*å’Œ\s*([A-D])\s*æ˜¯', ["é€‰é¡¹Xå’ŒYæ˜¯"]),
            (r'æ—¢æœ‰\s*([A-D])\s*ä¹Ÿæœ‰\s*([A-D])', ["æ—¢æœ‰Xä¹Ÿæœ‰Y"]),
            (r'åŒ…æ‹¬\s*([A-D])\s*ä»¥åŠ\s*([A-D])', ["åŒ…æ‹¬Xä»¥åŠY"]),
            (r'([A-D])[,ï¼Œã€]([A-D])[,ï¼Œã€]([A-D]).*éƒ½', ["A,B,Céƒ½"]),
        ]
        
        for pattern, desc in specific_patterns:
            match = re.search(pattern, answer_text_upper)
            if match:
                # ä»åŒ¹é…ç»„ä¸­ç›´æ¥æå–é€‰é¡¹
                options = [g for g in match.groups() if g in "ABCD"]
                if len(options) >= 2:
                    print(f"âœ… ç²¾ç¡®æ¨¡å¼åŒ¹é…({desc[0]}): {','.join(sorted(options))}")
                    return sorted(options)
        
        # 2. æ£€æµ‹è¿æ¥è¯çš„æ¨¡å¼ (åŒ…å«è¿æ¥è¯å’Œè‡³å°‘2ä¸ªé€‰é¡¹)
        connectors = ["å’Œ", "ä¸", "ä»¥åŠ", "è¿˜æœ‰", "ä¹Ÿæœ‰", "åŒ…æ‹¬", "æ¶µç›–"]
        
        # å¦‚æœæ–‡æœ¬ä¸­åŒ…å«è¿æ¥è¯ä¸”å­˜åœ¨å¤šä¸ªé€‰é¡¹
        has_connector = any(word in answer_lower for word in connectors)
        has_multiple_options = len(set(choices)) >= 2
        
        if has_connector and has_multiple_options:
            # å¦‚æœæ˜¯"Aå’ŒB"æˆ–"Aä¸B"ç­‰è¿ç»­æ¨¡å¼
            for option1 in "ABCD":
                for option2 in "ABCD":
                    if option1 != option2:
                        # æ£€æŸ¥æ˜¯å¦æœ‰å½¢å¦‚"Aå’ŒB"çš„æ¨¡å¼
                        for conn in ["å’Œ", "ä¸", "ã€", "ï¼Œ", ","]:
                            pattern = f"{option1}\\s*{conn}\\s*{option2}"
                            if re.search(pattern, answer_text_upper):
                                print(f"âœ… è¿æ¥è¯åŒ¹é…({option1}{conn}{option2}): {option1},{option2}")
                                return sorted([option1, option2])
            
            # å¦‚æœæ‰¾ä¸åˆ°å…·ä½“çš„è¿æ¥è¯æ¨¡å¼ï¼Œä½†æœ‰è¿æ¥è¯å’Œå¤šä¸ªé€‰é¡¹ï¼Œè¿”å›æ‰€æœ‰é€‰é¡¹
            unique_choices = sorted(list(set(choices)))
            print(f"âœ… åŸºäºè¿æ¥è¯å’Œå¤šé€‰é¡¹æå–: {','.join(unique_choices)}")
            return unique_choices
        
        # 3. æ£€æµ‹"éƒ½æ˜¯æ­£ç¡®é€‰é¡¹"æˆ–"éƒ½æ­£ç¡®"æ ¼å¼
        if "éƒ½æ˜¯æ­£ç¡®" in answer_text_upper or "éƒ½æ­£ç¡®" in answer_text_upper:
            if has_multiple_options:
                print(f"âœ… æå–ä¸å®šé¡¹é€‰æ‹©é¢˜ç­”æ¡ˆ(éƒ½æ˜¯æ­£ç¡®æ ¼å¼): {','.join(sorted(set(choices)))}")
                return sorted(list(set(choices)))
        
        # 4. æ ‡å‡†æ ¼å¼çš„å¤šé€‰é¢˜ç­”æ¡ˆæ¨¡å¼
        multi_patterns = [
            # æ˜ç¡®çš„å¤šé€‰ç­”æ¡ˆå£°æ˜
            r'æ­£ç¡®ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]\s*([A-D][,ï¼Œã€\.ï¼›;]*[A-D][,ï¼Œã€\.ï¼›;]*[A-D]?[,ï¼Œã€\.ï¼›;]*[A-D]?)',
            r'ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]\s*([A-D][,ï¼Œã€\.ï¼›;]*[A-D][,ï¼Œã€\.ï¼›;]*[A-D]?[,ï¼Œã€\.ï¼›;]*[A-D]?)',
            r'é€‰æ‹©\s*([A-D][,ï¼Œã€\.ï¼›;]*[A-D][,ï¼Œã€\.ï¼›;]*[A-D]?[,ï¼Œã€\.ï¼›;]*[A-D]?)',
            r'åº”è¯¥é€‰æ‹©\s*([A-D][,ï¼Œã€\.ï¼›;]*[A-D][,ï¼Œã€\.ï¼›;]*[A-D]?[,ï¼Œã€\.ï¼›;]*[A-D]?)',
            
            # ç®€å•çš„å¤šé€‰ç­”æ¡ˆæ ¼å¼
            r'([A-D][,ï¼Œã€]+[A-D][,ï¼Œã€]*[A-D]?[,ï¼Œã€]*[A-D]?)\s*æ­£ç¡®',
            r'æ­£ç¡®ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D][,ï¼Œã€]+[A-D][,ï¼Œã€]*[A-D]?[,ï¼Œã€]*[A-D]?)',
            
            # ç‰¹æ®Šè¡¨è¾¾æ–¹å¼çš„å¤šé€‰
            r'ç­”æ¡ˆä¸º[ï¼š:]\s*([A-D][,ï¼Œã€\.ï¼›;]*[A-D])',
        ]
        
        for i, pattern in enumerate(multi_patterns):
            matches = re.findall(pattern, answer_text_upper)
            if matches:
                # æå–æ‰€æœ‰é€‰é¡¹å­—æ¯ï¼ˆA-Dï¼‰ï¼Œå¿½ç•¥åˆ†éš”ç¬¦
                choice_str = matches[0].strip()
                pattern_choices = re.findall(r'[A-D]', choice_str)
                
                if pattern_choices and len(set(pattern_choices)) > 1:  # ç¡®è®¤æœ‰å¤šä¸ªä¸åŒé€‰é¡¹
                    print(f"âœ… æå–ä¸å®šé¡¹é€‰æ‹©é¢˜ç­”æ¡ˆ: {','.join(sorted(set(pattern_choices)))} (å¤šé€‰æ¨¡å¼{i+1})")
                    return sorted(list(set(pattern_choices)))  # å»é‡å¹¶æ’åº
        
        # 5. æ£€æŸ¥å¤šä¸ªæ­£ç¡®é€‰é¡¹
        correct_options = []
        for option in ['A', 'B', 'C', 'D']:
            option_patterns = [
                f"{option}[^A-D]*æ­£ç¡®",
                f"é€‰é¡¹{option}[^A-D]*æ­£ç¡®",
                f"{option}[^A-D]*æ˜¯æ­£ç¡®çš„",
                f"{option}[^A-D]*é€‰æ‹©",
                f"{option}[^A-D]*å¯¹",  # æ·»åŠ "å¯¹"çš„æ£€æµ‹
                f"{option}[^A-D]*æ˜¯å¯¹çš„",  # æ·»åŠ "æ˜¯å¯¹çš„"çš„æ£€æµ‹
            ]
            for pattern in option_patterns:
                if re.search(pattern, answer_text_upper):
                    correct_options.append(option)
                    break
        
        if len(correct_options) > 1:
            print(f"âœ… é€šè¿‡å¤šé€‰é¡¹åˆ†ææå–ç­”æ¡ˆ: {','.join(sorted(correct_options))}")
            return sorted(correct_options)
        
        # 6. å•é€‰é¢˜æ¨¡å¼
        single_patterns = [
            # æ˜ç¡®çš„ç­”æ¡ˆå£°æ˜
            r'æ­£ç¡®ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]\s*([A-D])',
            r'ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]\s*([A-D])',
            r'é€‰æ‹©\s*([A-D])',
            r'åº”è¯¥é€‰æ‹©?\s*([A-D])',
            r'ç­”æ¡ˆåº”è¯¥[æ˜¯ä¸º]?\s*([A-D])',
            
            # åˆ†æç»“è®º
            r'å› æ­¤[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            r'æ‰€ä»¥[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            r'ç»¼ä¸Šæ‰€è¿°[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            r'ç»¼åˆåˆ†æ[,ï¼Œ]?\s*ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            
            # é€‰é¡¹åˆ†æ
            r'é€‰é¡¹\s*([A-D])\s*[æ˜¯ä¸º]?æ­£ç¡®',
            r'([A-D])\s*é€‰é¡¹[æ˜¯ä¸º]?æ­£ç¡®',
            r'([A-D])\s*æ˜¯æ­£ç¡®çš„',
            r'([A-D])\s*æ­£ç¡®',
            
            # æ ¼å¼åŒ–ç­”æ¡ˆ
            r'[é€‰ç­”]\s*([A-D])',
            r'ç­”æ¡ˆ[:ï¼š]\s*([A-D])',
            r'^([A-D])[.ã€ï¼Œ]',  # ä»¥é€‰é¡¹å¼€å¤´
            
            # åœ¨å¥å­ä¸­çš„é€‰é¡¹
            r'\b([A-D])\b.*?æ­£ç¡®',
            r'é€‰æ‹©.*?([A-D])',
        ]
        
        for i, pattern in enumerate(single_patterns):
            matches = re.findall(pattern, answer_text_upper)
            if matches:
                choice = matches[0].strip()
                if choice in ['A', 'B', 'C', 'D']:
                    print(f"âœ… æå–é€‰æ‹©é¢˜ç­”æ¡ˆ: {choice} (å•é€‰æ¨¡å¼{i+1})")
                    return [choice]
        
        # 7. æ”¹è¿›ï¼šæ£€æŸ¥æœ€åä¸€å¥è¯ä¸­çš„é€‰é¡¹
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', answer_text_clean)
        for sentence in reversed(sentences):  # ä»æœ€åä¸€å¥å¼€å§‹
            if sentence.strip():
                sentence_upper = sentence.upper()
                
                # å°è¯•å¤šé€‰æ¨¡å¼
                for pattern in multi_patterns[:4]:  # ä½¿ç”¨å‰4ä¸ªé«˜ä¼˜å…ˆçº§å¤šé€‰æ¨¡å¼
                    matches = re.findall(pattern, sentence_upper)
                    if matches:
                        choice_str = matches[0].strip()
                        sent_choices = re.findall(r'[A-D]', choice_str)
                        if sent_choices and len(set(sent_choices)) > 1:
                            print(f"âœ… ä»å¥å­ä¸­æå–ä¸å®šé¡¹é€‰æ‹©é¢˜ç­”æ¡ˆ: {','.join(sorted(set(sent_choices)))}")
                            return sorted(list(set(sent_choices)))
                
                # å°è¯•å•é€‰æ¨¡å¼
                for pattern in single_patterns[:8]:  # ä½¿ç”¨å‰8ä¸ªé«˜ä¼˜å…ˆçº§å•é€‰æ¨¡å¼
                    matches = re.findall(pattern, sentence_upper)
                    if matches:
                        choice = matches[0].strip()
                        if choice in ['A', 'B', 'C', 'D']:
                            print(f"âœ… ä»å¥å­ä¸­æå–é€‰æ‹©é¢˜ç­”æ¡ˆ: {choice}")
                            return [choice]
        
        # 8. åŸºäºå‡ºç°é¢‘ç‡å’Œä½ç½®çš„æ¨æµ‹
        if choices:
            # ç»Ÿè®¡æ¯ä¸ªé€‰é¡¹å‡ºç°çš„æ¬¡æ•°
            choice_counts = {}
            for choice in choices:
                choice_counts[choice] = choice_counts.get(choice, 0) + 1
            
            # é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„ï¼Œå¦‚æœå¹³å±€åˆ™é€‰æ‹©æœ€åå‡ºç°çš„
            if choice_counts:
                max_count = max(choice_counts.values())
                frequent_choices = [c for c, count in choice_counts.items() if count == max_count]
                
                # åœ¨é¢‘ç¹é€‰é¡¹ä¸­é€‰æ‹©æœ€åå‡ºç°çš„
                for choice in reversed(choices):
                    if choice in frequent_choices:
                        print(f"âœ… åŸºäºé¢‘ç‡æå–é€‰æ‹©é¢˜ç­”æ¡ˆ: {choice}")
                        return [choice]
        
        # 9. æœ€åå°è¯•ï¼šåŸºäºå…³é”®è¯æ¨æµ‹
        if any(word in answer_lower for word in ['ç¬¬ä¸€', 'é¦–å…ˆ', 'æœ€åˆ']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: A")
            return ["A"]
        elif any(word in answer_lower for word in ['ç¬¬äºŒ', 'å…¶æ¬¡', 'å¦å¤–']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: B")
            return ["B"]
        elif any(word in answer_lower for word in ['ç¬¬ä¸‰', 'å†è€…', 'æ­¤å¤–']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: C")
            return ["C"]
        elif any(word in answer_lower for word in ['ç¬¬å››', 'æœ€å', 'æœ€ç»ˆ']):
            print("âš ï¸ åŸºäºå…³é”®è¯æ¨æµ‹ç­”æ¡ˆ: D")
            return ["D"]
        
        # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤ç­”æ¡ˆ
        print(f"âš ï¸ æ— æ³•ä»ç­”æ¡ˆä¸­æå–é€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤ç­”æ¡ˆA")
        print(f"åŸæ–‡: {answer_text[:200]}...")
        return ["A"]  # é»˜è®¤é€‰æ‹©A

    def validate_result_file(self, result_file: str):
        """éªŒè¯ç»“æœæ–‡ä»¶æ ¼å¼"""
        print("ğŸ” éªŒè¯ç»“æœæ–‡ä»¶æ ¼å¼...")
        
        try:
            choice_count = 0
            qa_count = 0
            
            with open(result_file, 'r', encoding='utf-8') as f:
                for line_no, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        data = json.loads(line)
                        
                        # æ£€æŸ¥å¿…éœ€å­—æ®µ
                        if 'id' not in data or 'answer' not in data:
                            print(f"âŒ ç¬¬{line_no}è¡Œç¼ºå°‘å¿…éœ€å­—æ®µ: {line}")
                            continue
                        
                        # ç»Ÿè®¡ç­”æ¡ˆç±»å‹
                        answer = data['answer']
                        if isinstance(answer, list):
                            choice_count += 1
                        else:
                            qa_count += 1
                            
                    except json.JSONDecodeError as e:
                        print(f"âŒ ç¬¬{line_no}è¡ŒJSONæ ¼å¼é”™è¯¯: {e}")
            
            print(f"âœ… æ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
            print(f"   é€‰æ‹©é¢˜: {choice_count} é“")
            print(f"   é—®ç­”é¢˜: {qa_count} é“")
            print(f"   æ€»è®¡: {choice_count + qa_count} é“")
            
            # æ˜¾ç¤ºå‰å‡ è¡Œç¤ºä¾‹
            print("\nğŸ“ æ–‡ä»¶å†…å®¹ç¤ºä¾‹:")
            with open(result_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= 3:  # åªæ˜¾ç¤ºå‰3è¡Œ
                        break
                    print(f"   {line.strip()}")
                        
        except Exception as e:
            print(f"âŒ éªŒè¯æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def save_raw_llm_outputs(self, results: List[Dict[str, Any]], output_file: str = None):
        """ä¿å­˜å¤§æ¨¡å‹åŸå§‹è¾“å‡ºåˆ°å•ç‹¬çš„JSONæ–‡ä»¶ï¼Œä¾¿äºéªŒè¯ç¨‹åºæ˜¯å¦æ­£å¸¸è°ƒç”¨å¤§æ¨¡å‹"""
        if output_file is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = f"{self.config.OUTPUT_DIR}/raw_llm_outputs_optimized_{timestamp}.json"
            
        output_path = Path(output_file)
        output_path.parent.mkdir(exist_ok=True)
        
        try:
            # æå–æ¯ä¸ªé—®é¢˜çš„IDå’Œå¤§æ¨¡å‹åŸå§‹è¾“å‡º
            raw_outputs = []
            for result in results:
                raw_outputs.append({
                    "id": result.get("id", "unknown"),
                    "category": result.get("category", "æœªçŸ¥"),
                    "question": result.get("question", ""),
                    "content": result.get("content", ""),
                    "raw_llm_output": result.get("raw_llm_output", "")
                })
                
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(raw_outputs, f, ensure_ascii=False, indent=2)
                
            print(f"ğŸ’¾ å¤§æ¨¡å‹åŸå§‹è¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤§æ¨¡å‹åŸå§‹è¾“å‡ºå¤±è´¥: {e}")

    def cleanup_intermediate_files(self, resume: bool = False):
        """æ¸…ç†æ—§çš„ä¸­é—´æ–‡ä»¶"""
        if resume:
            print("ğŸ”„ æ–­ç‚¹ç»­è·‘æ¨¡å¼ï¼šä¿ç•™ä¸­é—´æ–‡ä»¶")
            return
            
        print("ğŸ§¹ æ¸…ç†æ—§çš„ä¸­é—´æ–‡ä»¶...")
        
        output_dir = Path(self.config.OUTPUT_DIR)
        if not output_dir.exists():
            return
            
        # æ¸…ç†æ‰¹æ¬¡ç»“æœæ–‡ä»¶
        batch_files = list(output_dir.glob("batch_results*.json"))
        for file in batch_files:
            try:
                file.unlink()
                print(f"   âœ… åˆ é™¤: {file.name}")
            except Exception as e:
                print(f"   âŒ åˆ é™¤å¤±è´¥ {file.name}: {e}")
        
        if batch_files:
            print(f"æ¸…ç†äº† {len(batch_files)} ä¸ªä¸­é—´æ–‡ä»¶")
        else:
            print("æ²¡æœ‰éœ€è¦æ¸…ç†çš„ä¸­é—´æ–‡ä»¶")

    def run_test(self, force_rebuild: bool = False, batch_size: int = None, start_idx: int = 0, end_idx: int = None, resume: bool = False):
        """è¿è¡Œå®Œæ•´æµ‹è¯• - ä¼˜åŒ–ç‰ˆ"""
        print("å¼€å§‹è¿è¡Œé‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”æµ‹è¯• - ä¼˜åŒ–ç‰ˆ")
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸­é—´æ–‡ä»¶
        output_dir = Path(self.config.OUTPUT_DIR)
        if output_dir.exists():
            batch_files = list(output_dir.glob("batch_results_optimized_*.json"))
            if batch_files and not resume:
                print(f"\nå‘ç° {len(batch_files)} ä¸ªå·²æœ‰çš„æ‰¹æ¬¡ç»“æœæ–‡ä»¶:")
                for i, file in enumerate(sorted(batch_files)[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"   - {file.name}")
                if len(batch_files) > 5:
                    print(f"   - ... ç­‰å…± {len(batch_files)} ä¸ªæ–‡ä»¶")
                
                # æç¤ºç”¨æˆ·é€‰æ‹©æ“ä½œ
                choice = input("\nè¯·é€‰æ‹©æ“ä½œ: \n1. åˆ é™¤è¿™äº›æ–‡ä»¶å¹¶é‡æ–°å¼€å§‹ \n2. ä¿ç•™æ–‡ä»¶å¹¶ä»æ–­ç‚¹ç»­è·‘ \nè¯·è¾“å…¥é€‰æ‹©(1/2): ").strip()
                if choice == '2':
                    resume = True
                    print("å·²é€‰æ‹©æ–­ç‚¹ç»­è·‘æ¨¡å¼")
                else:
                    print("å·²é€‰æ‹©åˆ é™¤æ–‡ä»¶å¹¶é‡æ–°å¼€å§‹")
        
        # æ¸…ç†æ—§çš„ä¸­é—´æ–‡ä»¶ï¼ˆå¦‚æœä¸æ˜¯æ–­ç‚¹ç»­è·‘æ¨¡å¼ï¼‰
        self.cleanup_intermediate_files(resume=resume)
        
        # å¦‚æœæ˜¯æ–­ç‚¹ç»­è·‘æ¨¡å¼ï¼Œæ£€æŸ¥ä¹‹å‰çš„æ‰¹æ¬¡ç»“æœå¹¶åŠ è½½
        previous_results = []
        if resume:
            print("ğŸ“‹ æ–­ç‚¹ç»­è·‘æ¨¡å¼ï¼šæ£€æŸ¥ä¹‹å‰çš„æ‰¹æ¬¡ç»“æœ...")
            if output_dir.exists():
                batch_files = list(output_dir.glob("batch_results_optimized_*.json"))
                if batch_files:
                    print(f"æ‰¾åˆ° {len(batch_files)} ä¸ªæ‰¹æ¬¡ç»“æœæ–‡ä»¶")
                    
                    # æ”¶é›†å·²å¤„ç†çš„æ‰¹æ¬¡ç´¢å¼•
                    processed_batches = []
                    for file in batch_files:
                        # ä»æ–‡ä»¶åæå–æ‰¹æ¬¡ä¿¡æ¯
                        try:
                            match = re.search(r'batch_results_optimized_(\d+)_(\d+)', file.name)
                            if match:
                                batch_start = int(match.group(1))
                                batch_end = int(match.group(2))
                                processed_batches.append((batch_start, batch_end, file))
                                print(f"   å‘ç°æ‰¹æ¬¡ {batch_start}-{batch_end} çš„ç»“æœæ–‡ä»¶: {file.name}")
                        except Exception as e:
                            print(f"   âš ï¸ è§£ææ–‡ä»¶åå¤±è´¥: {file.name}, é”™è¯¯: {e}")
                    
                    # æŒ‰ç…§æ‰¹æ¬¡å¼€å§‹ä½ç½®æ’åº
                    processed_batches.sort(key=lambda x: x[0])
                    
                    # åŠ è½½å·²å¤„ç†çš„æ‰¹æ¬¡ç»“æœ
                    for batch_start, batch_end, file in processed_batches:
                        try:
                            with open(file, 'r', encoding='utf-8') as f:
                                batch_data = json.load(f)
                                if isinstance(batch_data, list) and batch_data:
                                    previous_results.extend(batch_data)
                                    print(f"   âœ… å·²åŠ è½½æ‰¹æ¬¡ {batch_start}-{batch_end} çš„ {len(batch_data)} æ¡ç»“æœ")
                                    
                                    # å¦‚æœè¿™ä¸ªæ‰¹æ¬¡ç»“æŸç´¢å¼•å¤§äºå½“å‰å¼€å§‹ç´¢å¼•ï¼Œæ›´æ–°å¼€å§‹ç´¢å¼•
                                    if batch_end >= start_idx:
                                        new_start_idx = batch_end + 1
                                        print(f"   ğŸ“Œ æ›´æ–°èµ·å§‹ç´¢å¼•ï¼š{start_idx} -> {new_start_idx}")
                                        start_idx = new_start_idx
                        except Exception as e:
                            print(f"   âŒ åŠ è½½ {file.name} å¤±è´¥: {e}")
                    
                    print(f"å…±åŠ è½½äº† {len(previous_results)} æ¡ä¹‹å‰çš„ç»“æœ")
                    
                    if previous_results:
                        # æ ¹æ®IDæ’åº
                        previous_results.sort(key=lambda x: x.get('id', 0))
                        print(f"å°†ä»ç´¢å¼• {start_idx} ç»§ç»­å¤„ç†")
                else:
                    print("æ²¡æœ‰æ‰¾åˆ°ä¹‹å‰çš„æ‰¹æ¬¡ç»“æœæ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹å¤„ç†")
        
        # ç”Ÿæˆæœ¬æ¬¡è¿è¡Œçš„å”¯ä¸€æ ‡è¯†
        run_timestamp = time.strftime("%Y%m%d_%H%M%S")
        print(f"ğŸ·ï¸ æœ¬æ¬¡è¿è¡Œæ ‡è¯†: {run_timestamp}")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        if not self.initialize():
            return False
            
        # æ„å»ºçŸ¥è¯†åº“
        if not self.build_knowledge_base(force_rebuild=force_rebuild):
            return False
            
        # åŠ è½½æµ‹è¯•æ•°æ®
        questions = self.load_test_data()
        if not questions:
            print("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•æ•°æ®")
            return False
            
        # è®¾ç½®æ‰¹å¤„ç†å¤§å°
        if batch_size is None:
            batch_size = self.config.BATCH_SIZE
            
        # è®¾ç½®å¤„ç†èŒƒå›´
        if end_idx is None or end_idx > len(questions):
            end_idx = len(questions)
            
        print(f"å°†å¤„ç† {end_idx - start_idx} ä¸ªé—®é¢˜ (ç´¢å¼• {start_idx} åˆ° {end_idx - 1})")
        
        # å¦‚æœå¼€å§‹ç´¢å¼•å·²ç»è¾¾åˆ°æˆ–è¶…è¿‡ç»“æŸç´¢å¼•ï¼Œè¯´æ˜æ‰€æœ‰æ‰¹æ¬¡å·²å¤„ç†å®Œ
        if start_idx >= end_idx:
            print("ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å·²å¤„ç†å®Œæ¯•ï¼Œç›´æ¥ç”Ÿæˆæœ€ç»ˆç»“æœ")
            all_results = previous_results
        else:
            # åˆ†æ‰¹å¤„ç†
            all_results = previous_results.copy()  # åŒ…å«ä¹‹å‰çš„ç»“æœ
            for batch_start in range(start_idx, end_idx, batch_size):
                batch_end = min(batch_start + batch_size, end_idx)
                
                print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_start}-{batch_end-1}")
                batch_results = self.process_batch(questions, batch_start, batch_end)
                all_results.extend(batch_results)
                
                # ä¿å­˜ä¸­é—´ç»“æœï¼ˆä¸ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶ï¼‰
                intermediate_file = f"{self.config.OUTPUT_DIR}/batch_results_optimized_{batch_start}_{batch_end-1}_{run_timestamp}.json"
                self.save_results(batch_results, intermediate_file, generate_competition_format=False)
                
                print(f"âœ… æ‰¹æ¬¡ {batch_start}-{batch_end-1} å¤„ç†å®Œæˆ")
        
        # ä¿å­˜æœ€ç»ˆç»“æœï¼ˆç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶ï¼‰
        print(f"\nğŸ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆç»“æœ...")
        final_result_file = f"{self.config.OUTPUT_DIR}/final_results_optimized_{run_timestamp}.json"
        competition_result_file = f"result_optimized_{run_timestamp}.json"
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        self.save_results(all_results, final_result_file, generate_competition_format=False)
        
        # ä¿å­˜å¤§æ¨¡å‹åŸå§‹è¾“å‡º
        raw_llm_output_file = f"{self.config.OUTPUT_DIR}/raw_llm_outputs_optimized_{run_timestamp}.json"
        self.save_raw_llm_outputs(all_results, raw_llm_output_file)
        
        # ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶
        self.save_competition_format_with_filename(all_results, competition_result_file)
        
        # åŒæ—¶ç”Ÿæˆé»˜è®¤åç§°çš„result.jsonï¼ˆè¦†ç›–æ—§ç‰ˆæœ¬ï¼‰
        self.save_competition_format_with_filename(all_results, "result.json")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_statistics(all_results)
        
        print(f"\nğŸ¯ ä¼˜åŒ–ç‰ˆæ¯”èµ›æ–‡ä»¶å·²ç”Ÿæˆ:")
        print(f"   - {competition_result_file} (å¸¦æ—¶é—´æˆ³)")
        print(f"   - result.json (é»˜è®¤æ–‡ä»¶)")
        print(f"   - {raw_llm_output_file} (å¤§æ¨¡å‹åŸå§‹è¾“å‡º)")
        print("ğŸ‰ ä¼˜åŒ–ç‰ˆæµ‹è¯•å®Œæˆï¼æœŸå¾…æ›´é«˜çš„åˆ†æ•°ï¼")
        return True
    
    def save_competition_format_with_filename(self, results: List[Dict[str, Any]], filename: str):
        """ä¿å­˜æ¯”èµ›æ ¼å¼æ–‡ä»¶åˆ°æŒ‡å®šæ–‡ä»¶å"""
        print(f"\nğŸ¯ ç”Ÿæˆæ¯”èµ›æäº¤æ ¼å¼æ–‡ä»¶: {filename}")
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                for result in results:
                    # æå–åŸºæœ¬ä¿¡æ¯
                    question_id = result.get('id')
                    category = result.get('category', 'é—®ç­”é¢˜')
                    answer = result.get('answer', '')
                    
                    # å¤„ç†ç­”æ¡ˆæ ¼å¼
                    if category == 'é€‰æ‹©é¢˜':
                        # ä»ç­”æ¡ˆä¸­æå–é€‰é¡¹ï¼ˆAã€Bã€Cã€Dç­‰ï¼‰
                        processed_answer = self.extract_choice_answer(answer)
                    else:
                        # é—®ç­”é¢˜ç›´æ¥ä½¿ç”¨æ–‡æœ¬ç­”æ¡ˆ
                        processed_answer = answer.strip()
                    
                    # æ„å»ºæ¯”èµ›æ ¼å¼çš„JSONå¯¹è±¡
                    competition_result = {
                        "id": question_id,
                        "answer": processed_answer
                    }
                    
                    # å†™å…¥æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
                    json.dump(competition_result, f, ensure_ascii=False)
                    f.write('\n')
            
            print(f"âœ… æ¯”èµ›æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {filename}")
            
            # éªŒè¯æ–‡ä»¶æ ¼å¼
            self.validate_result_file(filename)
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¯”èµ›æ ¼å¼æ–‡ä»¶å¤±è´¥: {e}")
    
    def print_statistics(self, results: List[Dict[str, Any]]):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š ä¼˜åŒ–ç‰ˆæµ‹è¯•ç»Ÿè®¡ä¿¡æ¯")
        print("="*60)
        
        total_questions = len(results)
        choice_questions = sum(1 for r in results if r.get('category') == 'é€‰æ‹©é¢˜')
        qa_questions = sum(1 for r in results if r.get('category') == 'é—®ç­”é¢˜')
        error_count = sum(1 for r in results if 'error' in r)
        
        print(f"æ€»é—®é¢˜æ•°: {total_questions}")
        print(f"é€‰æ‹©é¢˜æ•°: {choice_questions}")
        print(f"é—®ç­”é¢˜æ•°: {qa_questions}")
        print(f"å¤„ç†å¤±è´¥æ•°: {error_count}")
        print(f"æˆåŠŸç‡: {((total_questions - error_count) / total_questions * 100):.2f}%")
        
        # ç»Ÿè®¡å¹³å‡æ£€ç´¢æºæ•°é‡
        avg_sources = sum(r.get('num_sources', 0) for r in results if 'error' not in r) / max(1, total_questions - error_count)
        print(f"å¹³å‡æ£€ç´¢æºæ•°é‡: {avg_sources:.2f}")
        
        print(f"\nğŸ¯ ä¼˜åŒ–å‚æ•°ä½¿ç”¨æƒ…å†µ:")
        print(f"   æ–‡æ¡£åˆ‡ç‰‡å¤§å°: {self.config.CHUNK_SIZE}")
        print(f"   æ£€ç´¢TOP-K: {self.config.TOP_K}")
        print(f"   æ‰¹æ¬¡å¤§å°: {self.config.BATCH_SIZE}")
        print(f"   æœ€å¤§ç”Ÿæˆé•¿åº¦: {self.config.MAX_TOKENS}")
        
        # æ˜¾ç¤ºå‘é‡æ•°æ®åº“ç»Ÿè®¡
        if self.rag_engine:
            vector_stats = self.rag_engine.get_vector_db_stats()
            print(f"\nğŸ” å‘é‡æ•°æ®åº“ç»Ÿè®¡:")
            for key, value in vector_stats.items():
                print(f"  {key}: {value}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é‡‘èç›‘ç®¡åˆ¶åº¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆ")
    parser.add_argument("--force-rebuild", action="store_true", help="å¼ºåˆ¶é‡å»ºç´¢å¼•")
    parser.add_argument("--batch-size", type=int, default=5, help="æ‰¹å¤„ç†å¤§å°(ä¼˜åŒ–ç‰ˆé»˜è®¤5)")
    parser.add_argument("--start-idx", type=int, default=0, help="å¼€å§‹ç´¢å¼•")
    parser.add_argument("--end-idx", type=int, help="ç»“æŸç´¢å¼•")
    parser.add_argument("--resume", action="store_true", help="æ–­ç‚¹ç»­è·‘ï¼Œä¿ç•™ä¹‹å‰çš„ä¸­é—´ç»“æœ")
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¼˜åŒ–ç‰ˆç³»ç»Ÿå®ä¾‹
    qa_system = FinancialQASystemOptimized()
    
    # è¿è¡Œä¼˜åŒ–ç‰ˆæµ‹è¯•
    qa_system.run_test(
        force_rebuild=args.force_rebuild,
        batch_size=args.batch_size,
        start_idx=args.start_idx,
        end_idx=args.end_idx,
        resume=args.resume
    )


if __name__ == "__main__":
    main() 