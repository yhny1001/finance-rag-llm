"""
æ–‡æ¡£åˆ‡ç‰‡è´¨é‡åˆ†æè„šæœ¬
åˆ†æå‘é‡æ•°æ®åº“ä¸­æ–‡æ¡£ç‰‡æ®µçš„è´¨é‡é—®é¢˜ï¼Œæ‰¾å‡ºå¾—åˆ†ä½çš„æ ¹å› 
"""

import json
import random
from collections import defaultdict, Counter
from vector_db import VectorDatabase
from config import Config

def analyze_chunk_quality():
    """åˆ†ææ–‡æ¡£åˆ‡ç‰‡è´¨é‡"""
    print("ğŸ” æ–‡æ¡£åˆ‡ç‰‡è´¨é‡åˆ†æ")
    print("=" * 60)
    
    # åŠ è½½å‘é‡æ•°æ®åº“
    vdb = VectorDatabase()
    if not vdb.load_from_disk():
        print("âŒ æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“")
        return
    
    print("âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
    stats = vdb.get_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    print("\nğŸ“Š æ–‡æ¡£ç‰‡æ®µé•¿åº¦åˆ†æ")
    print("-" * 40)
    
    # åˆ†ææ‰€æœ‰æ–‡æ¡£ç‰‡æ®µ
    chunk_lengths = []
    short_chunks = []  # é•¿åº¦å°äº50çš„çŸ­ç‰‡æ®µ
    empty_chunks = []  # ç©ºæˆ–å‡ ä¹ç©ºçš„ç‰‡æ®µ
    title_chunks = []  # å¯èƒ½æ˜¯æ ‡é¢˜çš„ç‰‡æ®µ
    
    total_chunks = len(vdb.document_store)
    print(f"æ€»æ–‡æ¡£ç‰‡æ®µæ•°: {total_chunks}")
    
    for chunk_id, chunk_data in vdb.document_store.items():
        text = chunk_data.get('text', '')
        length = len(text)
        chunk_lengths.append(length)
        
        if length < 50:
            short_chunks.append((chunk_id, text))
        
        if length < 10:
            empty_chunks.append((chunk_id, text))
        
        # æ£€æµ‹å¯èƒ½çš„æ ‡é¢˜ç‰‡æ®µï¼ˆçŸ­ä¸”åŒ…å«æ ‡ç‚¹ï¼‰
        if length < 100 and ('ã€Š' in text or 'ã€‹' in text or 'çš„é€šçŸ¥' in text):
            title_chunks.append((chunk_id, text))
    
    # é•¿åº¦ç»Ÿè®¡
    avg_length = sum(chunk_lengths) / len(chunk_lengths)
    sorted_lengths = sorted(chunk_lengths)
    median_length = sorted_lengths[len(sorted_lengths) // 2]
    
    print(f"å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
    print(f"ä¸­ä½æ•°é•¿åº¦: {median_length} å­—ç¬¦")
    print(f"æœ€çŸ­ç‰‡æ®µ: {min(chunk_lengths)} å­—ç¬¦")
    print(f"æœ€é•¿ç‰‡æ®µ: {max(chunk_lengths)} å­—ç¬¦")
    
    # é•¿åº¦åˆ†å¸ƒ
    length_ranges = {
        "æçŸ­(0-10)": len([l for l in chunk_lengths if 0 <= l <= 10]),
        "å¾ˆçŸ­(11-50)": len([l for l in chunk_lengths if 11 <= l <= 50]),
        "çŸ­(51-200)": len([l for l in chunk_lengths if 51 <= l <= 200]),
        "ä¸­ç­‰(201-500)": len([l for l in chunk_lengths if 201 <= l <= 500]),
        "é•¿(501+)": len([l for l in chunk_lengths if l > 500])
    }
    
    print(f"\nğŸ“ˆ é•¿åº¦åˆ†å¸ƒ:")
    for range_name, count in length_ranges.items():
        percentage = (count / total_chunks) * 100
        print(f"  {range_name}: {count} ä¸ª ({percentage:.1f}%)")
    
    # é—®é¢˜ç‰‡æ®µåˆ†æ
    print(f"\nâš ï¸ é—®é¢˜ç‰‡æ®µåˆ†æ")
    print("-" * 40)
    print(f"çŸ­ç‰‡æ®µ(<50å­—ç¬¦): {len(short_chunks)} ä¸ª ({len(short_chunks)/total_chunks*100:.1f}%)")
    print(f"ç©ºç‰‡æ®µ(<10å­—ç¬¦): {len(empty_chunks)} ä¸ª ({len(empty_chunks)/total_chunks*100:.1f}%)")
    print(f"ç–‘ä¼¼æ ‡é¢˜ç‰‡æ®µ: {len(title_chunks)} ä¸ª ({len(title_chunks)/total_chunks*100:.1f}%)")
    
    # æ˜¾ç¤ºé—®é¢˜ç‰‡æ®µæ ·ä¾‹
    if short_chunks:
        print(f"\nğŸ” çŸ­ç‰‡æ®µæ ·ä¾‹ (å‰10ä¸ª):")
        for i, (chunk_id, text) in enumerate(short_chunks[:10]):
            print(f"  {i+1}. [{chunk_id}] (é•¿åº¦{len(text)}): {repr(text)}")
    
    if title_chunks:
        print(f"\nğŸ“„ ç–‘ä¼¼æ ‡é¢˜ç‰‡æ®µæ ·ä¾‹ (å‰10ä¸ª):")
        for i, (chunk_id, text) in enumerate(title_chunks[:10]):
            print(f"  {i+1}. [{chunk_id}] (é•¿åº¦{len(text)}): {repr(text)}")
    
    return analyze_specific_queries(vdb)

def analyze_specific_queries(vdb):
    """åˆ†æç‰¹å®šæŸ¥è¯¢çš„æ£€ç´¢è´¨é‡"""
    print(f"\nğŸ¯ ç‰¹å®šæŸ¥è¯¢åˆ†æ")
    print("=" * 60)
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        ("æµåŠ¨æ€§è¦†ç›–ç‡LCRæœ€ä½è¦æ±‚", ["æµåŠ¨æ€§è¦†ç›–ç‡", "LCR", "100%", "ä¸ä½äº"]),
        ("é“¶è¡Œæ æ†ç‡ç›‘ç®¡è¦æ±‚", ["æ æ†ç‡", "4%", "ä¸ä½äº", "ä¸€çº§èµ„æœ¬"]),
        ("é“¶è¡Œé—´åŒä¸šæ‹†å€Ÿåˆ©ç‡", ["åŒä¸šæ‹†å€Ÿ", "åˆ©ç‡", "é“¶è¡Œé—´", "èµ„é‡‘"])
    ]
    
    for query, expected_keywords in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        print("-" * 30)
        
        # æ‰§è¡Œæœç´¢
        results = vdb.search(query, top_k=5)
        
        if not results:
            print("âŒ æ— æœç´¢ç»“æœ")
            continue
        
        print(f"æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")
        
        # åˆ†ææ¯ä¸ªç»“æœ
        for i, result in enumerate(results):
            text = result.get('text', '')
            score = result.get('score', 0)
            chunk_id = result.get('chunk_id', '')
            
            print(f"\nç»“æœ {i+1}:")
            print(f"  ç‰‡æ®µID: {chunk_id}")
            print(f"  ç›¸ä¼¼åº¦: {score:.3f}")
            print(f"  é•¿åº¦: {len(text)} å­—ç¬¦")
            print(f"  å†…å®¹: {repr(text[:100])}...")
            
            # å…³é”®è¯åŒ¹é…åˆ†æ
            found_keywords = [kw for kw in expected_keywords if kw in text]
            print(f"  æœŸæœ›å…³é”®è¯: {expected_keywords}")
            print(f"  åŒ¹é…å…³é”®è¯: {found_keywords}")
            print(f"  åŒ¹é…ç‡: {len(found_keywords)/len(expected_keywords)*100:.1f}%")
            
            # å†…å®¹è´¨é‡è¯„ä¼°
            has_numbers = any(char.isdigit() for char in text)
            has_percentage = '%' in text
            has_punctuation = any(p in text for p in ['ã€‚', 'ï¼Œ', 'ï¼›', 'ï¼š'])
            
            print(f"  åŒ…å«æ•°å­—: {has_numbers}")
            print(f"  åŒ…å«ç™¾åˆ†æ¯”: {has_percentage}")
            print(f"  æœ‰æ ‡ç‚¹ç¬¦å·: {has_punctuation}")
            
            # åˆ¤æ–­å†…å®¹ç±»å‹
            if len(text) < 50:
                content_type = "ç‰‡æ®µè¿‡çŸ­"
            elif 'é€šçŸ¥' in text and len(text) < 100:
                content_type = "ç–‘ä¼¼æ ‡é¢˜"
            elif not has_punctuation:
                content_type = "å¯èƒ½æ˜¯è¡¨æ ¼ç‰‡æ®µ"
            else:
                content_type = "æ­£å¸¸å†…å®¹"
            
            print(f"  å†…å®¹ç±»å‹: {content_type}")

def analyze_config_impact():
    """åˆ†æé…ç½®å‚æ•°å¯¹åˆ‡ç‰‡è´¨é‡çš„å½±å“"""
    print(f"\nâš™ï¸ é…ç½®å‚æ•°åˆ†æ")
    print("=" * 60)
    
    print(f"å½“å‰é…ç½®:")
    print(f"  CHUNK_SIZE: {Config.CHUNK_SIZE}")
    print(f"  CHUNK_OVERLAP: {Config.CHUNK_OVERLAP}")
    print(f"  TOP_K: {Config.TOP_K}")
    print(f"  SIMILARITY_THRESHOLD: {Config.SIMILARITY_THRESHOLD}")
    
    print(f"\nğŸ“‹ åˆ‡ç‰‡é…ç½®å»ºè®®:")
    if Config.CHUNK_SIZE < 800:
        print(f"  âš ï¸ CHUNK_SIZE ({Config.CHUNK_SIZE}) è¿‡å°ï¼Œå»ºè®®å¢åŠ åˆ° 1000-1200")
        print(f"     å°åˆ‡ç‰‡å®¹æ˜“å¯¼è‡´ä¿¡æ¯ä¸å®Œæ•´ï¼Œç‰¹åˆ«æ˜¯å¤æ‚çš„ç›‘ç®¡æ¡æ–‡")
    
    if Config.CHUNK_OVERLAP < 100:
        print(f"  âš ï¸ CHUNK_OVERLAP ({Config.CHUNK_OVERLAP}) è¿‡å°ï¼Œå»ºè®®å¢åŠ åˆ° 150-200")
        print(f"     æ›´å¤§çš„é‡å æœ‰åŠ©äºä¿æŒè¯­ä¹‰è¿ç»­æ€§")
    
    if Config.TOP_K < 8:
        print(f"  âš ï¸ TOP_K ({Config.TOP_K}) è¿‡å°ï¼Œå»ºè®®å¢åŠ åˆ° 8-10")
        print(f"     å¢åŠ æ£€ç´¢æ•°é‡å¯ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡")

def recommend_solutions():
    """æ¨èè§£å†³æ–¹æ¡ˆ"""
    print(f"\nğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®")
    print("=" * 60)
    
    print(f"1. ğŸ”§ æ›´æ–°é…ç½®å‚æ•°")
    print(f"   - ä½¿ç”¨ config_improved.py æ›¿ä»£ config.py")
    print(f"   - CHUNK_SIZE: 512 â†’ 1000")
    print(f"   - CHUNK_OVERLAP: 50 â†’ 200")
    print(f"   - TOP_K: 5 â†’ 10")
    
    print(f"\n2. ğŸ”„ é‡å»ºå‘é‡æ•°æ®åº“")
    print(f"   - python main_improved.py --force-rebuild")
    print(f"   - ä½¿ç”¨æ”¹è¿›çš„åˆ‡ç‰‡å‚æ•°é‡æ–°å¤„ç†æ–‡æ¡£")
    
    print(f"\n3. ğŸ“ æ–‡æ¡£é¢„å¤„ç†ä¼˜åŒ–")
    print(f"   - ç§»é™¤é¡µçœ‰é¡µè„šå’Œæ ‡é¢˜ç‰‡æ®µ")
    print(f"   - åˆå¹¶çŸ­æ®µè½ï¼Œç¡®ä¿è¯­ä¹‰å®Œæ•´æ€§")
    print(f"   - è¿‡æ»¤æ‰é•¿åº¦å°äº100å­—ç¬¦çš„ç‰‡æ®µ")
    
    print(f"\n4. ğŸ¯ æ£€ç´¢ä¼˜åŒ–")
    print(f"   - å®æ–½äºŒé˜¶æ®µæ£€ç´¢ï¼šç²—æ£€ç´¢ + é‡æ’åº")
    print(f"   - åŸºäºå…³é”®è¯è¦†ç›–ç‡è¿›è¡Œç»“æœè¿‡æ»¤")
    print(f"   - å¢åŠ åŒä¹‰è¯æ‰©å±•")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ–‡æ¡£åˆ‡ç‰‡è´¨é‡åˆ†æ")
    
    analyze_chunk_quality()
    analyze_config_impact() 
    recommend_solutions()
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"\nğŸ“Œ æ ¸å¿ƒé—®é¢˜æ€»ç»“:")
    print(f"1. åˆ‡ç‰‡å¤§å°è¿‡å° (512å­—ç¬¦) å¯¼è‡´ä¿¡æ¯åˆ†å‰²")
    print(f"2. æ–‡æ¡£é¢„å¤„ç†ä¸å½“ï¼Œä¿ç•™äº†æ ‡é¢˜å’Œç©ºç‰‡æ®µ")
    print(f"3. æ£€ç´¢å‚æ•°éœ€è¦ä¼˜åŒ–")
    print(f"\nğŸ¯ ç«‹å³è¡ŒåŠ¨:")
    print(f"1. ä¿®æ”¹ä¸»ç¨‹åºä½¿ç”¨ config_improved.py")
    print(f"2. é‡å»ºå‘é‡æ•°æ®åº“")
    print(f"3. é‡æ–°æµ‹è¯•æ£€ç´¢è´¨é‡")

if __name__ == "__main__":
    main() 